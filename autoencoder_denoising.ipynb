{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "inputs_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs=inputs_, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(inputs=maxpool1, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(inputs=maxpool2, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_images(encoded, size=(7,7), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(inputs=upsample1, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_images(conv4, size=(14,14), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(inputs=upsample2, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_images(conv5, size=(28,28), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(inputs=upsample3, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits = tf.layers.conv2d(inputs=conv6, filters=1, kernel_size=(3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Training loss: 0.6836\n",
      "Epoch: 1/10... Training loss: 0.6552\n",
      "Epoch: 1/10... Training loss: 0.6168\n",
      "Epoch: 1/10... Training loss: 0.5689\n",
      "Epoch: 1/10... Training loss: 0.5173\n",
      "Epoch: 1/10... Training loss: 0.4732\n",
      "Epoch: 1/10... Training loss: 0.5110\n",
      "Epoch: 1/10... Training loss: 0.5080\n",
      "Epoch: 1/10... Training loss: 0.5036\n",
      "Epoch: 1/10... Training loss: 0.4622\n",
      "Epoch: 1/10... Training loss: 0.4342\n",
      "Epoch: 1/10... Training loss: 0.4363\n",
      "Epoch: 1/10... Training loss: 0.4339\n",
      "Epoch: 1/10... Training loss: 0.4157\n",
      "Epoch: 1/10... Training loss: 0.4083\n",
      "Epoch: 1/10... Training loss: 0.3912\n",
      "Epoch: 1/10... Training loss: 0.3755\n",
      "Epoch: 1/10... Training loss: 0.3676\n",
      "Epoch: 1/10... Training loss: 0.3640\n",
      "Epoch: 1/10... Training loss: 0.3431\n",
      "Epoch: 1/10... Training loss: 0.3225\n",
      "Epoch: 1/10... Training loss: 0.3152\n",
      "Epoch: 1/10... Training loss: 0.3045\n",
      "Epoch: 1/10... Training loss: 0.3009\n",
      "Epoch: 1/10... Training loss: 0.2854\n",
      "Epoch: 1/10... Training loss: 0.2922\n",
      "Epoch: 1/10... Training loss: 0.2835\n",
      "Epoch: 1/10... Training loss: 0.2761\n",
      "Epoch: 1/10... Training loss: 0.2624\n",
      "Epoch: 1/10... Training loss: 0.2738\n",
      "Epoch: 1/10... Training loss: 0.2651\n",
      "Epoch: 1/10... Training loss: 0.2574\n",
      "Epoch: 1/10... Training loss: 0.2665\n",
      "Epoch: 1/10... Training loss: 0.2670\n",
      "Epoch: 1/10... Training loss: 0.2740\n",
      "Epoch: 1/10... Training loss: 0.2656\n",
      "Epoch: 1/10... Training loss: 0.2597\n",
      "Epoch: 1/10... Training loss: 0.2585\n",
      "Epoch: 1/10... Training loss: 0.2581\n",
      "Epoch: 1/10... Training loss: 0.2671\n",
      "Epoch: 1/10... Training loss: 0.2508\n",
      "Epoch: 1/10... Training loss: 0.2508\n",
      "Epoch: 1/10... Training loss: 0.2570\n",
      "Epoch: 1/10... Training loss: 0.2449\n",
      "Epoch: 1/10... Training loss: 0.2522\n",
      "Epoch: 1/10... Training loss: 0.2418\n",
      "Epoch: 1/10... Training loss: 0.2501\n",
      "Epoch: 1/10... Training loss: 0.2535\n",
      "Epoch: 1/10... Training loss: 0.2480\n",
      "Epoch: 1/10... Training loss: 0.2414\n",
      "Epoch: 1/10... Training loss: 0.2347\n",
      "Epoch: 1/10... Training loss: 0.2459\n",
      "Epoch: 1/10... Training loss: 0.2417\n",
      "Epoch: 1/10... Training loss: 0.2308\n",
      "Epoch: 1/10... Training loss: 0.2420\n",
      "Epoch: 1/10... Training loss: 0.2414\n",
      "Epoch: 1/10... Training loss: 0.2462\n",
      "Epoch: 1/10... Training loss: 0.2371\n",
      "Epoch: 1/10... Training loss: 0.2385\n",
      "Epoch: 1/10... Training loss: 0.2280\n",
      "Epoch: 1/10... Training loss: 0.2348\n",
      "Epoch: 1/10... Training loss: 0.2306\n",
      "Epoch: 1/10... Training loss: 0.2304\n",
      "Epoch: 1/10... Training loss: 0.2312\n",
      "Epoch: 1/10... Training loss: 0.2280\n",
      "Epoch: 1/10... Training loss: 0.2298\n",
      "Epoch: 1/10... Training loss: 0.2221\n",
      "Epoch: 1/10... Training loss: 0.2313\n",
      "Epoch: 1/10... Training loss: 0.2269\n",
      "Epoch: 1/10... Training loss: 0.2204\n",
      "Epoch: 1/10... Training loss: 0.2326\n",
      "Epoch: 1/10... Training loss: 0.2180\n",
      "Epoch: 1/10... Training loss: 0.2270\n",
      "Epoch: 1/10... Training loss: 0.2289\n",
      "Epoch: 1/10... Training loss: 0.2168\n",
      "Epoch: 1/10... Training loss: 0.2258\n",
      "Epoch: 1/10... Training loss: 0.2241\n",
      "Epoch: 1/10... Training loss: 0.2207\n",
      "Epoch: 1/10... Training loss: 0.2239\n",
      "Epoch: 1/10... Training loss: 0.2257\n",
      "Epoch: 1/10... Training loss: 0.2206\n",
      "Epoch: 1/10... Training loss: 0.2348\n",
      "Epoch: 1/10... Training loss: 0.2214\n",
      "Epoch: 1/10... Training loss: 0.2252\n",
      "Epoch: 1/10... Training loss: 0.2203\n",
      "Epoch: 1/10... Training loss: 0.2202\n",
      "Epoch: 1/10... Training loss: 0.2215\n",
      "Epoch: 1/10... Training loss: 0.2160\n",
      "Epoch: 1/10... Training loss: 0.2158\n",
      "Epoch: 1/10... Training loss: 0.2141\n",
      "Epoch: 1/10... Training loss: 0.2143\n",
      "Epoch: 1/10... Training loss: 0.2213\n",
      "Epoch: 1/10... Training loss: 0.2172\n",
      "Epoch: 1/10... Training loss: 0.2168\n",
      "Epoch: 1/10... Training loss: 0.2160\n",
      "Epoch: 1/10... Training loss: 0.2234\n",
      "Epoch: 1/10... Training loss: 0.2185\n",
      "Epoch: 1/10... Training loss: 0.2131\n",
      "Epoch: 1/10... Training loss: 0.2126\n",
      "Epoch: 1/10... Training loss: 0.2120\n",
      "Epoch: 1/10... Training loss: 0.2068\n",
      "Epoch: 1/10... Training loss: 0.2096\n",
      "Epoch: 1/10... Training loss: 0.2081\n",
      "Epoch: 1/10... Training loss: 0.2080\n",
      "Epoch: 1/10... Training loss: 0.2128\n",
      "Epoch: 1/10... Training loss: 0.2171\n",
      "Epoch: 1/10... Training loss: 0.2092\n",
      "Epoch: 1/10... Training loss: 0.2106\n",
      "Epoch: 1/10... Training loss: 0.2071\n",
      "Epoch: 1/10... Training loss: 0.1982\n",
      "Epoch: 1/10... Training loss: 0.2141\n",
      "Epoch: 1/10... Training loss: 0.2126\n",
      "Epoch: 1/10... Training loss: 0.2137\n",
      "Epoch: 1/10... Training loss: 0.2051\n",
      "Epoch: 1/10... Training loss: 0.1992\n",
      "Epoch: 1/10... Training loss: 0.2107\n",
      "Epoch: 1/10... Training loss: 0.2033\n",
      "Epoch: 1/10... Training loss: 0.2160\n",
      "Epoch: 1/10... Training loss: 0.2102\n",
      "Epoch: 1/10... Training loss: 0.2120\n",
      "Epoch: 1/10... Training loss: 0.2084\n",
      "Epoch: 1/10... Training loss: 0.2012\n",
      "Epoch: 1/10... Training loss: 0.2076\n",
      "Epoch: 1/10... Training loss: 0.2033\n",
      "Epoch: 1/10... Training loss: 0.2034\n",
      "Epoch: 1/10... Training loss: 0.1980\n",
      "Epoch: 1/10... Training loss: 0.2071\n",
      "Epoch: 1/10... Training loss: 0.2033\n",
      "Epoch: 1/10... Training loss: 0.2117\n",
      "Epoch: 1/10... Training loss: 0.2043\n",
      "Epoch: 1/10... Training loss: 0.2151\n",
      "Epoch: 1/10... Training loss: 0.2105\n",
      "Epoch: 1/10... Training loss: 0.1965\n",
      "Epoch: 1/10... Training loss: 0.2029\n",
      "Epoch: 1/10... Training loss: 0.2025\n",
      "Epoch: 1/10... Training loss: 0.1978\n",
      "Epoch: 1/10... Training loss: 0.2052\n",
      "Epoch: 1/10... Training loss: 0.2035\n",
      "Epoch: 1/10... Training loss: 0.1998\n",
      "Epoch: 1/10... Training loss: 0.1916\n",
      "Epoch: 1/10... Training loss: 0.2025\n",
      "Epoch: 1/10... Training loss: 0.2006\n",
      "Epoch: 1/10... Training loss: 0.2006\n",
      "Epoch: 1/10... Training loss: 0.1916\n",
      "Epoch: 1/10... Training loss: 0.1989\n",
      "Epoch: 1/10... Training loss: 0.1961\n",
      "Epoch: 1/10... Training loss: 0.1950\n",
      "Epoch: 1/10... Training loss: 0.2000\n",
      "Epoch: 1/10... Training loss: 0.1963\n",
      "Epoch: 1/10... Training loss: 0.1902\n",
      "Epoch: 1/10... Training loss: 0.2045\n",
      "Epoch: 1/10... Training loss: 0.1925\n",
      "Epoch: 1/10... Training loss: 0.2001\n",
      "Epoch: 1/10... Training loss: 0.1963\n",
      "Epoch: 1/10... Training loss: 0.1889\n",
      "Epoch: 1/10... Training loss: 0.1931\n",
      "Epoch: 1/10... Training loss: 0.2000\n",
      "Epoch: 1/10... Training loss: 0.1972\n",
      "Epoch: 1/10... Training loss: 0.1867\n",
      "Epoch: 1/10... Training loss: 0.1889\n",
      "Epoch: 1/10... Training loss: 0.1960\n",
      "Epoch: 1/10... Training loss: 0.1957\n",
      "Epoch: 1/10... Training loss: 0.1988\n",
      "Epoch: 1/10... Training loss: 0.1939\n",
      "Epoch: 1/10... Training loss: 0.1829\n",
      "Epoch: 1/10... Training loss: 0.1926\n",
      "Epoch: 1/10... Training loss: 0.1882\n",
      "Epoch: 1/10... Training loss: 0.1944\n",
      "Epoch: 1/10... Training loss: 0.1866\n",
      "Epoch: 1/10... Training loss: 0.1953\n",
      "Epoch: 1/10... Training loss: 0.1876\n",
      "Epoch: 1/10... Training loss: 0.1893\n",
      "Epoch: 1/10... Training loss: 0.1821\n",
      "Epoch: 1/10... Training loss: 0.1921\n",
      "Epoch: 1/10... Training loss: 0.1894\n",
      "Epoch: 1/10... Training loss: 0.1898\n",
      "Epoch: 1/10... Training loss: 0.1853\n",
      "Epoch: 1/10... Training loss: 0.1874\n",
      "Epoch: 1/10... Training loss: 0.1881\n",
      "Epoch: 1/10... Training loss: 0.1862\n",
      "Epoch: 1/10... Training loss: 0.1896\n",
      "Epoch: 1/10... Training loss: 0.1871\n",
      "Epoch: 1/10... Training loss: 0.1835\n",
      "Epoch: 1/10... Training loss: 0.1832\n",
      "Epoch: 1/10... Training loss: 0.1870\n",
      "Epoch: 1/10... Training loss: 0.1813\n",
      "Epoch: 1/10... Training loss: 0.1894\n",
      "Epoch: 1/10... Training loss: 0.1894\n",
      "Epoch: 1/10... Training loss: 0.1824\n",
      "Epoch: 1/10... Training loss: 0.1876\n",
      "Epoch: 1/10... Training loss: 0.1817\n",
      "Epoch: 1/10... Training loss: 0.1767\n",
      "Epoch: 1/10... Training loss: 0.1934\n",
      "Epoch: 1/10... Training loss: 0.1840\n",
      "Epoch: 1/10... Training loss: 0.1829\n",
      "Epoch: 1/10... Training loss: 0.1822\n",
      "Epoch: 1/10... Training loss: 0.1921\n",
      "Epoch: 1/10... Training loss: 0.1811\n",
      "Epoch: 1/10... Training loss: 0.1995\n",
      "Epoch: 1/10... Training loss: 0.1926\n",
      "Epoch: 1/10... Training loss: 0.1897\n",
      "Epoch: 1/10... Training loss: 0.1903\n",
      "Epoch: 1/10... Training loss: 0.1806\n",
      "Epoch: 1/10... Training loss: 0.1890\n",
      "Epoch: 1/10... Training loss: 0.1852\n",
      "Epoch: 1/10... Training loss: 0.1856\n",
      "Epoch: 1/10... Training loss: 0.1882\n",
      "Epoch: 1/10... Training loss: 0.1842\n",
      "Epoch: 1/10... Training loss: 0.1890\n",
      "Epoch: 1/10... Training loss: 0.1851\n",
      "Epoch: 1/10... Training loss: 0.1836\n",
      "Epoch: 1/10... Training loss: 0.1881\n",
      "Epoch: 1/10... Training loss: 0.1868\n",
      "Epoch: 1/10... Training loss: 0.1807\n",
      "Epoch: 1/10... Training loss: 0.1823\n",
      "Epoch: 1/10... Training loss: 0.1736\n",
      "Epoch: 1/10... Training loss: 0.1890\n",
      "Epoch: 1/10... Training loss: 0.1926\n",
      "Epoch: 1/10... Training loss: 0.1784\n",
      "Epoch: 1/10... Training loss: 0.1729\n",
      "Epoch: 1/10... Training loss: 0.1749\n",
      "Epoch: 1/10... Training loss: 0.1789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Training loss: 0.1817\n",
      "Epoch: 1/10... Training loss: 0.1770\n",
      "Epoch: 1/10... Training loss: 0.1775\n",
      "Epoch: 1/10... Training loss: 0.1825\n",
      "Epoch: 1/10... Training loss: 0.1772\n",
      "Epoch: 1/10... Training loss: 0.1723\n",
      "Epoch: 1/10... Training loss: 0.1788\n",
      "Epoch: 1/10... Training loss: 0.1757\n",
      "Epoch: 1/10... Training loss: 0.1811\n",
      "Epoch: 1/10... Training loss: 0.1809\n",
      "Epoch: 1/10... Training loss: 0.1819\n",
      "Epoch: 1/10... Training loss: 0.1850\n",
      "Epoch: 1/10... Training loss: 0.1771\n",
      "Epoch: 1/10... Training loss: 0.1763\n",
      "Epoch: 1/10... Training loss: 0.1840\n",
      "Epoch: 1/10... Training loss: 0.1686\n",
      "Epoch: 1/10... Training loss: 0.1782\n",
      "Epoch: 1/10... Training loss: 0.1716\n",
      "Epoch: 1/10... Training loss: 0.1761\n",
      "Epoch: 1/10... Training loss: 0.1728\n",
      "Epoch: 1/10... Training loss: 0.1753\n",
      "Epoch: 1/10... Training loss: 0.1742\n",
      "Epoch: 1/10... Training loss: 0.1729\n",
      "Epoch: 1/10... Training loss: 0.1781\n",
      "Epoch: 1/10... Training loss: 0.1739\n",
      "Epoch: 1/10... Training loss: 0.1686\n",
      "Epoch: 1/10... Training loss: 0.1637\n",
      "Epoch: 1/10... Training loss: 0.1700\n",
      "Epoch: 1/10... Training loss: 0.1835\n",
      "Epoch: 1/10... Training loss: 0.1769\n",
      "Epoch: 1/10... Training loss: 0.1740\n",
      "Epoch: 1/10... Training loss: 0.1751\n",
      "Epoch: 1/10... Training loss: 0.1775\n",
      "Epoch: 1/10... Training loss: 0.1778\n",
      "Epoch: 1/10... Training loss: 0.1806\n",
      "Epoch: 1/10... Training loss: 0.1698\n",
      "Epoch: 1/10... Training loss: 0.1810\n",
      "Epoch: 1/10... Training loss: 0.1756\n",
      "Epoch: 1/10... Training loss: 0.1687\n",
      "Epoch: 1/10... Training loss: 0.1755\n",
      "Epoch: 1/10... Training loss: 0.1847\n",
      "Epoch: 1/10... Training loss: 0.1657\n",
      "Epoch: 1/10... Training loss: 0.1756\n",
      "Epoch: 1/10... Training loss: 0.1723\n",
      "Epoch: 1/10... Training loss: 0.1730\n",
      "Epoch: 1/10... Training loss: 0.1666\n",
      "Epoch: 1/10... Training loss: 0.1746\n",
      "Epoch: 1/10... Training loss: 0.1719\n",
      "Epoch: 1/10... Training loss: 0.1724\n",
      "Epoch: 1/10... Training loss: 0.1676\n",
      "Epoch: 1/10... Training loss: 0.1746\n",
      "Epoch: 1/10... Training loss: 0.1722\n",
      "Epoch: 1/10... Training loss: 0.1682\n",
      "Epoch: 1/10... Training loss: 0.1735\n",
      "Epoch: 1/10... Training loss: 0.1712\n",
      "Epoch: 1/10... Training loss: 0.1713\n",
      "Epoch: 1/10... Training loss: 0.1647\n",
      "Epoch: 1/10... Training loss: 0.1723\n",
      "Epoch: 1/10... Training loss: 0.1769\n",
      "Epoch: 1/10... Training loss: 0.1699\n",
      "Epoch: 1/10... Training loss: 0.1717\n",
      "Epoch: 1/10... Training loss: 0.1738\n",
      "Epoch: 1/10... Training loss: 0.1682\n",
      "Epoch: 1/10... Training loss: 0.1701\n",
      "Epoch: 1/10... Training loss: 0.1623\n",
      "Epoch: 1/10... Training loss: 0.1720\n",
      "Epoch: 1/10... Training loss: 0.1739\n",
      "Epoch: 1/10... Training loss: 0.1629\n",
      "Epoch: 1/10... Training loss: 0.1736\n",
      "Epoch: 1/10... Training loss: 0.1690\n",
      "Epoch: 1/10... Training loss: 0.1693\n",
      "Epoch: 1/10... Training loss: 0.1761\n",
      "Epoch: 1/10... Training loss: 0.1737\n",
      "Epoch: 1/10... Training loss: 0.1742\n",
      "Epoch: 1/10... Training loss: 0.1625\n",
      "Epoch: 1/10... Training loss: 0.1673\n",
      "Epoch: 1/10... Training loss: 0.1624\n",
      "Epoch: 1/10... Training loss: 0.1667\n",
      "Epoch: 1/10... Training loss: 0.1674\n",
      "Epoch: 1/10... Training loss: 0.1673\n",
      "Epoch: 1/10... Training loss: 0.1612\n",
      "Epoch: 1/10... Training loss: 0.1649\n",
      "Epoch: 1/10... Training loss: 0.1696\n",
      "Epoch: 1/10... Training loss: 0.1669\n",
      "Epoch: 1/10... Training loss: 0.1738\n",
      "Epoch: 1/10... Training loss: 0.1588\n",
      "Epoch: 1/10... Training loss: 0.1609\n",
      "Epoch: 1/10... Training loss: 0.1660\n",
      "Epoch: 1/10... Training loss: 0.1599\n",
      "Epoch: 1/10... Training loss: 0.1657\n",
      "Epoch: 1/10... Training loss: 0.1630\n",
      "Epoch: 1/10... Training loss: 0.1707\n",
      "Epoch: 1/10... Training loss: 0.1647\n",
      "Epoch: 1/10... Training loss: 0.1522\n",
      "Epoch: 1/10... Training loss: 0.1689\n",
      "Epoch: 1/10... Training loss: 0.1663\n",
      "Epoch: 1/10... Training loss: 0.1660\n",
      "Epoch: 1/10... Training loss: 0.1705\n",
      "Epoch: 1/10... Training loss: 0.1686\n",
      "Epoch: 1/10... Training loss: 0.1622\n",
      "Epoch: 1/10... Training loss: 0.1708\n",
      "Epoch: 1/10... Training loss: 0.1683\n",
      "Epoch: 1/10... Training loss: 0.1690\n",
      "Epoch: 1/10... Training loss: 0.1646\n",
      "Epoch: 1/10... Training loss: 0.1650\n",
      "Epoch: 1/10... Training loss: 0.1652\n",
      "Epoch: 1/10... Training loss: 0.1712\n",
      "Epoch: 1/10... Training loss: 0.1625\n",
      "Epoch: 1/10... Training loss: 0.1548\n",
      "Epoch: 1/10... Training loss: 0.1639\n",
      "Epoch: 1/10... Training loss: 0.1622\n",
      "Epoch: 1/10... Training loss: 0.1625\n",
      "Epoch: 1/10... Training loss: 0.1665\n",
      "Epoch: 1/10... Training loss: 0.1635\n",
      "Epoch: 1/10... Training loss: 0.1647\n",
      "Epoch: 1/10... Training loss: 0.1650\n",
      "Epoch: 1/10... Training loss: 0.1658\n",
      "Epoch: 1/10... Training loss: 0.1722\n",
      "Epoch: 1/10... Training loss: 0.1686\n",
      "Epoch: 1/10... Training loss: 0.1607\n",
      "Epoch: 1/10... Training loss: 0.1633\n",
      "Epoch: 1/10... Training loss: 0.1636\n",
      "Epoch: 1/10... Training loss: 0.1598\n",
      "Epoch: 1/10... Training loss: 0.1603\n",
      "Epoch: 1/10... Training loss: 0.1596\n",
      "Epoch: 1/10... Training loss: 0.1605\n",
      "Epoch: 1/10... Training loss: 0.1580\n",
      "Epoch: 1/10... Training loss: 0.1603\n",
      "Epoch: 1/10... Training loss: 0.1585\n",
      "Epoch: 1/10... Training loss: 0.1687\n",
      "Epoch: 1/10... Training loss: 0.1610\n",
      "Epoch: 1/10... Training loss: 0.1656\n",
      "Epoch: 1/10... Training loss: 0.1724\n",
      "Epoch: 1/10... Training loss: 0.1611\n",
      "Epoch: 1/10... Training loss: 0.1671\n",
      "Epoch: 1/10... Training loss: 0.1693\n",
      "Epoch: 1/10... Training loss: 0.1561\n",
      "Epoch: 1/10... Training loss: 0.1650\n",
      "Epoch: 1/10... Training loss: 0.1650\n",
      "Epoch: 1/10... Training loss: 0.1660\n",
      "Epoch: 1/10... Training loss: 0.1648\n",
      "Epoch: 1/10... Training loss: 0.1602\n",
      "Epoch: 1/10... Training loss: 0.1621\n",
      "Epoch: 1/10... Training loss: 0.1594\n",
      "Epoch: 1/10... Training loss: 0.1619\n",
      "Epoch: 1/10... Training loss: 0.1598\n",
      "Epoch: 1/10... Training loss: 0.1541\n",
      "Epoch: 1/10... Training loss: 0.1600\n",
      "Epoch: 1/10... Training loss: 0.1641\n",
      "Epoch: 1/10... Training loss: 0.1637\n",
      "Epoch: 1/10... Training loss: 0.1558\n",
      "Epoch: 1/10... Training loss: 0.1643\n",
      "Epoch: 1/10... Training loss: 0.1604\n",
      "Epoch: 1/10... Training loss: 0.1559\n",
      "Epoch: 1/10... Training loss: 0.1578\n",
      "Epoch: 1/10... Training loss: 0.1572\n",
      "Epoch: 1/10... Training loss: 0.1465\n",
      "Epoch: 1/10... Training loss: 0.1683\n",
      "Epoch: 1/10... Training loss: 0.1559\n",
      "Epoch: 1/10... Training loss: 0.1599\n",
      "Epoch: 1/10... Training loss: 0.1576\n",
      "Epoch: 1/10... Training loss: 0.1589\n",
      "Epoch: 1/10... Training loss: 0.1578\n",
      "Epoch: 1/10... Training loss: 0.1622\n",
      "Epoch: 1/10... Training loss: 0.1622\n",
      "Epoch: 1/10... Training loss: 0.1661\n",
      "Epoch: 1/10... Training loss: 0.1601\n",
      "Epoch: 1/10... Training loss: 0.1636\n",
      "Epoch: 1/10... Training loss: 0.1542\n",
      "Epoch: 1/10... Training loss: 0.1567\n",
      "Epoch: 1/10... Training loss: 0.1611\n",
      "Epoch: 1/10... Training loss: 0.1552\n",
      "Epoch: 1/10... Training loss: 0.1597\n",
      "Epoch: 1/10... Training loss: 0.1595\n",
      "Epoch: 1/10... Training loss: 0.1572\n",
      "Epoch: 1/10... Training loss: 0.1614\n",
      "Epoch: 1/10... Training loss: 0.1585\n",
      "Epoch: 1/10... Training loss: 0.1607\n",
      "Epoch: 1/10... Training loss: 0.1639\n",
      "Epoch: 1/10... Training loss: 0.1591\n",
      "Epoch: 1/10... Training loss: 0.1594\n",
      "Epoch: 1/10... Training loss: 0.1528\n",
      "Epoch: 1/10... Training loss: 0.1567\n",
      "Epoch: 1/10... Training loss: 0.1634\n",
      "Epoch: 1/10... Training loss: 0.1528\n",
      "Epoch: 1/10... Training loss: 0.1512\n",
      "Epoch: 1/10... Training loss: 0.1537\n",
      "Epoch: 1/10... Training loss: 0.1571\n",
      "Epoch: 1/10... Training loss: 0.1562\n",
      "Epoch: 1/10... Training loss: 0.1595\n",
      "Epoch: 1/10... Training loss: 0.1529\n",
      "Epoch: 1/10... Training loss: 0.1581\n",
      "Epoch: 1/10... Training loss: 0.1545\n",
      "Epoch: 1/10... Training loss: 0.1614\n",
      "Epoch: 1/10... Training loss: 0.1544\n",
      "Epoch: 1/10... Training loss: 0.1497\n",
      "Epoch: 1/10... Training loss: 0.1567\n",
      "Epoch: 1/10... Training loss: 0.1591\n",
      "Epoch: 1/10... Training loss: 0.1530\n",
      "Epoch: 1/10... Training loss: 0.1607\n",
      "Epoch: 1/10... Training loss: 0.1583\n",
      "Epoch: 1/10... Training loss: 0.1511\n",
      "Epoch: 1/10... Training loss: 0.1590\n",
      "Epoch: 1/10... Training loss: 0.1556\n",
      "Epoch: 1/10... Training loss: 0.1517\n",
      "Epoch: 1/10... Training loss: 0.1623\n",
      "Epoch: 1/10... Training loss: 0.1512\n",
      "Epoch: 1/10... Training loss: 0.1585\n",
      "Epoch: 1/10... Training loss: 0.1570\n",
      "Epoch: 1/10... Training loss: 0.1514\n",
      "Epoch: 1/10... Training loss: 0.1490\n",
      "Epoch: 1/10... Training loss: 0.1569\n",
      "Epoch: 1/10... Training loss: 0.1530\n",
      "Epoch: 1/10... Training loss: 0.1530\n",
      "Epoch: 1/10... Training loss: 0.1484\n",
      "Epoch: 1/10... Training loss: 0.1463\n",
      "Epoch: 1/10... Training loss: 0.1468\n",
      "Epoch: 1/10... Training loss: 0.1571\n",
      "Epoch: 1/10... Training loss: 0.1562\n",
      "Epoch: 1/10... Training loss: 0.1643\n",
      "Epoch: 1/10... Training loss: 0.1547\n",
      "Epoch: 1/10... Training loss: 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Training loss: 0.1526\n",
      "Epoch: 1/10... Training loss: 0.1555\n",
      "Epoch: 1/10... Training loss: 0.1526\n",
      "Epoch: 1/10... Training loss: 0.1563\n",
      "Epoch: 1/10... Training loss: 0.1511\n",
      "Epoch: 1/10... Training loss: 0.1484\n",
      "Epoch: 1/10... Training loss: 0.1524\n",
      "Epoch: 1/10... Training loss: 0.1611\n",
      "Epoch: 1/10... Training loss: 0.1577\n",
      "Epoch: 1/10... Training loss: 0.1452\n",
      "Epoch: 1/10... Training loss: 0.1558\n",
      "Epoch: 1/10... Training loss: 0.1561\n",
      "Epoch: 1/10... Training loss: 0.1563\n",
      "Epoch: 1/10... Training loss: 0.1580\n",
      "Epoch: 1/10... Training loss: 0.1483\n",
      "Epoch: 1/10... Training loss: 0.1550\n",
      "Epoch: 1/10... Training loss: 0.1473\n",
      "Epoch: 1/10... Training loss: 0.1517\n",
      "Epoch: 1/10... Training loss: 0.1484\n",
      "Epoch: 1/10... Training loss: 0.1528\n",
      "Epoch: 1/10... Training loss: 0.1520\n",
      "Epoch: 1/10... Training loss: 0.1588\n",
      "Epoch: 1/10... Training loss: 0.1523\n",
      "Epoch: 1/10... Training loss: 0.1542\n",
      "Epoch: 1/10... Training loss: 0.1572\n",
      "Epoch: 1/10... Training loss: 0.1522\n",
      "Epoch: 1/10... Training loss: 0.1587\n",
      "Epoch: 1/10... Training loss: 0.1437\n",
      "Epoch: 1/10... Training loss: 0.1472\n",
      "Epoch: 1/10... Training loss: 0.1491\n",
      "Epoch: 1/10... Training loss: 0.1494\n",
      "Epoch: 1/10... Training loss: 0.1475\n",
      "Epoch: 1/10... Training loss: 0.1488\n",
      "Epoch: 1/10... Training loss: 0.1627\n",
      "Epoch: 1/10... Training loss: 0.1502\n",
      "Epoch: 1/10... Training loss: 0.1519\n",
      "Epoch: 1/10... Training loss: 0.1584\n",
      "Epoch: 1/10... Training loss: 0.1526\n",
      "Epoch: 1/10... Training loss: 0.1575\n",
      "Epoch: 1/10... Training loss: 0.1577\n",
      "Epoch: 1/10... Training loss: 0.1532\n",
      "Epoch: 1/10... Training loss: 0.1538\n",
      "Epoch: 1/10... Training loss: 0.1543\n",
      "Epoch: 1/10... Training loss: 0.1528\n",
      "Epoch: 1/10... Training loss: 0.1597\n",
      "Epoch: 1/10... Training loss: 0.1486\n",
      "Epoch: 1/10... Training loss: 0.1567\n",
      "Epoch: 1/10... Training loss: 0.1456\n",
      "Epoch: 1/10... Training loss: 0.1504\n",
      "Epoch: 1/10... Training loss: 0.1540\n",
      "Epoch: 1/10... Training loss: 0.1431\n",
      "Epoch: 1/10... Training loss: 0.1480\n",
      "Epoch: 1/10... Training loss: 0.1534\n",
      "Epoch: 1/10... Training loss: 0.1506\n",
      "Epoch: 1/10... Training loss: 0.1510\n",
      "Epoch: 1/10... Training loss: 0.1493\n",
      "Epoch: 1/10... Training loss: 0.1459\n",
      "Epoch: 1/10... Training loss: 0.1433\n",
      "Epoch: 1/10... Training loss: 0.1457\n",
      "Epoch: 1/10... Training loss: 0.1415\n",
      "Epoch: 1/10... Training loss: 0.1451\n",
      "Epoch: 1/10... Training loss: 0.1502\n",
      "Epoch: 1/10... Training loss: 0.1524\n",
      "Epoch: 1/10... Training loss: 0.1537\n",
      "Epoch: 1/10... Training loss: 0.1431\n",
      "Epoch: 1/10... Training loss: 0.1383\n",
      "Epoch: 1/10... Training loss: 0.1466\n",
      "Epoch: 1/10... Training loss: 0.1483\n",
      "Epoch: 1/10... Training loss: 0.1553\n",
      "Epoch: 1/10... Training loss: 0.1472\n",
      "Epoch: 1/10... Training loss: 0.1483\n",
      "Epoch: 1/10... Training loss: 0.1560\n",
      "Epoch: 1/10... Training loss: 0.1515\n",
      "Epoch: 1/10... Training loss: 0.1477\n",
      "Epoch: 1/10... Training loss: 0.1463\n",
      "Epoch: 1/10... Training loss: 0.1452\n",
      "Epoch: 1/10... Training loss: 0.1479\n",
      "Epoch: 1/10... Training loss: 0.1529\n",
      "Epoch: 1/10... Training loss: 0.1509\n",
      "Epoch: 1/10... Training loss: 0.1511\n",
      "Epoch: 1/10... Training loss: 0.1463\n",
      "Epoch: 1/10... Training loss: 0.1426\n",
      "Epoch: 1/10... Training loss: 0.1532\n",
      "Epoch: 1/10... Training loss: 0.1434\n",
      "Epoch: 1/10... Training loss: 0.1473\n",
      "Epoch: 1/10... Training loss: 0.1529\n",
      "Epoch: 1/10... Training loss: 0.1535\n",
      "Epoch: 1/10... Training loss: 0.1435\n",
      "Epoch: 1/10... Training loss: 0.1493\n",
      "Epoch: 1/10... Training loss: 0.1468\n",
      "Epoch: 1/10... Training loss: 0.1526\n",
      "Epoch: 1/10... Training loss: 0.1467\n",
      "Epoch: 1/10... Training loss: 0.1504\n",
      "Epoch: 1/10... Training loss: 0.1535\n",
      "Epoch: 1/10... Training loss: 0.1493\n",
      "Epoch: 1/10... Training loss: 0.1491\n",
      "Epoch: 1/10... Training loss: 0.1447\n",
      "Epoch: 1/10... Training loss: 0.1487\n",
      "Epoch: 1/10... Training loss: 0.1506\n",
      "Epoch: 1/10... Training loss: 0.1483\n",
      "Epoch: 1/10... Training loss: 0.1522\n",
      "Epoch: 1/10... Training loss: 0.1489\n",
      "Epoch: 1/10... Training loss: 0.1502\n",
      "Epoch: 1/10... Training loss: 0.1437\n",
      "Epoch: 1/10... Training loss: 0.1470\n",
      "Epoch: 1/10... Training loss: 0.1483\n",
      "Epoch: 1/10... Training loss: 0.1472\n",
      "Epoch: 1/10... Training loss: 0.1449\n",
      "Epoch: 1/10... Training loss: 0.1456\n",
      "Epoch: 1/10... Training loss: 0.1418\n",
      "Epoch: 1/10... Training loss: 0.1400\n",
      "Epoch: 1/10... Training loss: 0.1431\n",
      "Epoch: 1/10... Training loss: 0.1491\n",
      "Epoch: 1/10... Training loss: 0.1470\n",
      "Epoch: 1/10... Training loss: 0.1478\n",
      "Epoch: 1/10... Training loss: 0.1561\n",
      "Epoch: 1/10... Training loss: 0.1533\n",
      "Epoch: 1/10... Training loss: 0.1487\n",
      "Epoch: 1/10... Training loss: 0.1429\n",
      "Epoch: 1/10... Training loss: 0.1545\n",
      "Epoch: 1/10... Training loss: 0.1526\n",
      "Epoch: 1/10... Training loss: 0.1488\n",
      "Epoch: 1/10... Training loss: 0.1475\n",
      "Epoch: 1/10... Training loss: 0.1500\n",
      "Epoch: 1/10... Training loss: 0.1436\n",
      "Epoch: 1/10... Training loss: 0.1462\n",
      "Epoch: 1/10... Training loss: 0.1538\n",
      "Epoch: 1/10... Training loss: 0.1537\n",
      "Epoch: 1/10... Training loss: 0.1411\n",
      "Epoch: 1/10... Training loss: 0.1471\n",
      "Epoch: 1/10... Training loss: 0.1433\n",
      "Epoch: 1/10... Training loss: 0.1462\n",
      "Epoch: 1/10... Training loss: 0.1463\n",
      "Epoch: 1/10... Training loss: 0.1528\n",
      "Epoch: 1/10... Training loss: 0.1488\n",
      "Epoch: 1/10... Training loss: 0.1512\n",
      "Epoch: 1/10... Training loss: 0.1445\n",
      "Epoch: 1/10... Training loss: 0.1450\n",
      "Epoch: 1/10... Training loss: 0.1385\n",
      "Epoch: 1/10... Training loss: 0.1454\n",
      "Epoch: 1/10... Training loss: 0.1434\n",
      "Epoch: 1/10... Training loss: 0.1497\n",
      "Epoch: 1/10... Training loss: 0.1499\n",
      "Epoch: 1/10... Training loss: 0.1405\n",
      "Epoch: 1/10... Training loss: 0.1477\n",
      "Epoch: 1/10... Training loss: 0.1536\n",
      "Epoch: 1/10... Training loss: 0.1435\n",
      "Epoch: 1/10... Training loss: 0.1398\n",
      "Epoch: 1/10... Training loss: 0.1470\n",
      "Epoch: 1/10... Training loss: 0.1532\n",
      "Epoch: 1/10... Training loss: 0.1482\n",
      "Epoch: 1/10... Training loss: 0.1443\n",
      "Epoch: 1/10... Training loss: 0.1497\n",
      "Epoch: 1/10... Training loss: 0.1495\n",
      "Epoch: 1/10... Training loss: 0.1465\n",
      "Epoch: 1/10... Training loss: 0.1473\n",
      "Epoch: 2/10... Training loss: 0.1461\n",
      "Epoch: 2/10... Training loss: 0.1454\n",
      "Epoch: 2/10... Training loss: 0.1511\n",
      "Epoch: 2/10... Training loss: 0.1532\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1486\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1432\n",
      "Epoch: 2/10... Training loss: 0.1423\n",
      "Epoch: 2/10... Training loss: 0.1450\n",
      "Epoch: 2/10... Training loss: 0.1455\n",
      "Epoch: 2/10... Training loss: 0.1401\n",
      "Epoch: 2/10... Training loss: 0.1461\n",
      "Epoch: 2/10... Training loss: 0.1435\n",
      "Epoch: 2/10... Training loss: 0.1466\n",
      "Epoch: 2/10... Training loss: 0.1474\n",
      "Epoch: 2/10... Training loss: 0.1431\n",
      "Epoch: 2/10... Training loss: 0.1433\n",
      "Epoch: 2/10... Training loss: 0.1508\n",
      "Epoch: 2/10... Training loss: 0.1394\n",
      "Epoch: 2/10... Training loss: 0.1461\n",
      "Epoch: 2/10... Training loss: 0.1479\n",
      "Epoch: 2/10... Training loss: 0.1450\n",
      "Epoch: 2/10... Training loss: 0.1476\n",
      "Epoch: 2/10... Training loss: 0.1506\n",
      "Epoch: 2/10... Training loss: 0.1420\n",
      "Epoch: 2/10... Training loss: 0.1456\n",
      "Epoch: 2/10... Training loss: 0.1475\n",
      "Epoch: 2/10... Training loss: 0.1456\n",
      "Epoch: 2/10... Training loss: 0.1449\n",
      "Epoch: 2/10... Training loss: 0.1453\n",
      "Epoch: 2/10... Training loss: 0.1541\n",
      "Epoch: 2/10... Training loss: 0.1413\n",
      "Epoch: 2/10... Training loss: 0.1477\n",
      "Epoch: 2/10... Training loss: 0.1464\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1454\n",
      "Epoch: 2/10... Training loss: 0.1481\n",
      "Epoch: 2/10... Training loss: 0.1420\n",
      "Epoch: 2/10... Training loss: 0.1442\n",
      "Epoch: 2/10... Training loss: 0.1445\n",
      "Epoch: 2/10... Training loss: 0.1424\n",
      "Epoch: 2/10... Training loss: 0.1432\n",
      "Epoch: 2/10... Training loss: 0.1404\n",
      "Epoch: 2/10... Training loss: 0.1468\n",
      "Epoch: 2/10... Training loss: 0.1419\n",
      "Epoch: 2/10... Training loss: 0.1434\n",
      "Epoch: 2/10... Training loss: 0.1471\n",
      "Epoch: 2/10... Training loss: 0.1463\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1454\n",
      "Epoch: 2/10... Training loss: 0.1476\n",
      "Epoch: 2/10... Training loss: 0.1414\n",
      "Epoch: 2/10... Training loss: 0.1533\n",
      "Epoch: 2/10... Training loss: 0.1448\n",
      "Epoch: 2/10... Training loss: 0.1470\n",
      "Epoch: 2/10... Training loss: 0.1468\n",
      "Epoch: 2/10... Training loss: 0.1456\n",
      "Epoch: 2/10... Training loss: 0.1452\n",
      "Epoch: 2/10... Training loss: 0.1482\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1443\n",
      "Epoch: 2/10... Training loss: 0.1415\n",
      "Epoch: 2/10... Training loss: 0.1427\n",
      "Epoch: 2/10... Training loss: 0.1445\n",
      "Epoch: 2/10... Training loss: 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1409\n",
      "Epoch: 2/10... Training loss: 0.1494\n",
      "Epoch: 2/10... Training loss: 0.1450\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1396\n",
      "Epoch: 2/10... Training loss: 0.1428\n",
      "Epoch: 2/10... Training loss: 0.1425\n",
      "Epoch: 2/10... Training loss: 0.1441\n",
      "Epoch: 2/10... Training loss: 0.1452\n",
      "Epoch: 2/10... Training loss: 0.1395\n",
      "Epoch: 2/10... Training loss: 0.1451\n",
      "Epoch: 2/10... Training loss: 0.1468\n",
      "Epoch: 2/10... Training loss: 0.1501\n",
      "Epoch: 2/10... Training loss: 0.1403\n",
      "Epoch: 2/10... Training loss: 0.1491\n",
      "Epoch: 2/10... Training loss: 0.1406\n",
      "Epoch: 2/10... Training loss: 0.1437\n",
      "Epoch: 2/10... Training loss: 0.1405\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1421\n",
      "Epoch: 2/10... Training loss: 0.1467\n",
      "Epoch: 2/10... Training loss: 0.1424\n",
      "Epoch: 2/10... Training loss: 0.1444\n",
      "Epoch: 2/10... Training loss: 0.1435\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1413\n",
      "Epoch: 2/10... Training loss: 0.1515\n",
      "Epoch: 2/10... Training loss: 0.1364\n",
      "Epoch: 2/10... Training loss: 0.1434\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1411\n",
      "Epoch: 2/10... Training loss: 0.1377\n",
      "Epoch: 2/10... Training loss: 0.1439\n",
      "Epoch: 2/10... Training loss: 0.1370\n",
      "Epoch: 2/10... Training loss: 0.1374\n",
      "Epoch: 2/10... Training loss: 0.1417\n",
      "Epoch: 2/10... Training loss: 0.1426\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1427\n",
      "Epoch: 2/10... Training loss: 0.1396\n",
      "Epoch: 2/10... Training loss: 0.1427\n",
      "Epoch: 2/10... Training loss: 0.1408\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1471\n",
      "Epoch: 2/10... Training loss: 0.1471\n",
      "Epoch: 2/10... Training loss: 0.1433\n",
      "Epoch: 2/10... Training loss: 0.1431\n",
      "Epoch: 2/10... Training loss: 0.1433\n",
      "Epoch: 2/10... Training loss: 0.1426\n",
      "Epoch: 2/10... Training loss: 0.1403\n",
      "Epoch: 2/10... Training loss: 0.1489\n",
      "Epoch: 2/10... Training loss: 0.1420\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1432\n",
      "Epoch: 2/10... Training loss: 0.1436\n",
      "Epoch: 2/10... Training loss: 0.1401\n",
      "Epoch: 2/10... Training loss: 0.1357\n",
      "Epoch: 2/10... Training loss: 0.1428\n",
      "Epoch: 2/10... Training loss: 0.1380\n",
      "Epoch: 2/10... Training loss: 0.1455\n",
      "Epoch: 2/10... Training loss: 0.1403\n",
      "Epoch: 2/10... Training loss: 0.1474\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1411\n",
      "Epoch: 2/10... Training loss: 0.1377\n",
      "Epoch: 2/10... Training loss: 0.1358\n",
      "Epoch: 2/10... Training loss: 0.1424\n",
      "Epoch: 2/10... Training loss: 0.1452\n",
      "Epoch: 2/10... Training loss: 0.1405\n",
      "Epoch: 2/10... Training loss: 0.1327\n",
      "Epoch: 2/10... Training loss: 0.1429\n",
      "Epoch: 2/10... Training loss: 0.1387\n",
      "Epoch: 2/10... Training loss: 0.1410\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1391\n",
      "Epoch: 2/10... Training loss: 0.1398\n",
      "Epoch: 2/10... Training loss: 0.1404\n",
      "Epoch: 2/10... Training loss: 0.1438\n",
      "Epoch: 2/10... Training loss: 0.1433\n",
      "Epoch: 2/10... Training loss: 0.1436\n",
      "Epoch: 2/10... Training loss: 0.1411\n",
      "Epoch: 2/10... Training loss: 0.1387\n",
      "Epoch: 2/10... Training loss: 0.1438\n",
      "Epoch: 2/10... Training loss: 0.1389\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1375\n",
      "Epoch: 2/10... Training loss: 0.1409\n",
      "Epoch: 2/10... Training loss: 0.1382\n",
      "Epoch: 2/10... Training loss: 0.1443\n",
      "Epoch: 2/10... Training loss: 0.1391\n",
      "Epoch: 2/10... Training loss: 0.1308\n",
      "Epoch: 2/10... Training loss: 0.1471\n",
      "Epoch: 2/10... Training loss: 0.1430\n",
      "Epoch: 2/10... Training loss: 0.1388\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1395\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1399\n",
      "Epoch: 2/10... Training loss: 0.1406\n",
      "Epoch: 2/10... Training loss: 0.1408\n",
      "Epoch: 2/10... Training loss: 0.1395\n",
      "Epoch: 2/10... Training loss: 0.1402\n",
      "Epoch: 2/10... Training loss: 0.1459\n",
      "Epoch: 2/10... Training loss: 0.1390\n",
      "Epoch: 2/10... Training loss: 0.1456\n",
      "Epoch: 2/10... Training loss: 0.1406\n",
      "Epoch: 2/10... Training loss: 0.1414\n",
      "Epoch: 2/10... Training loss: 0.1415\n",
      "Epoch: 2/10... Training loss: 0.1376\n",
      "Epoch: 2/10... Training loss: 0.1361\n",
      "Epoch: 2/10... Training loss: 0.1380\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1446\n",
      "Epoch: 2/10... Training loss: 0.1329\n",
      "Epoch: 2/10... Training loss: 0.1434\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1436\n",
      "Epoch: 2/10... Training loss: 0.1387\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1429\n",
      "Epoch: 2/10... Training loss: 0.1401\n",
      "Epoch: 2/10... Training loss: 0.1388\n",
      "Epoch: 2/10... Training loss: 0.1438\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1381\n",
      "Epoch: 2/10... Training loss: 0.1424\n",
      "Epoch: 2/10... Training loss: 0.1432\n",
      "Epoch: 2/10... Training loss: 0.1429\n",
      "Epoch: 2/10... Training loss: 0.1421\n",
      "Epoch: 2/10... Training loss: 0.1382\n",
      "Epoch: 2/10... Training loss: 0.1305\n",
      "Epoch: 2/10... Training loss: 0.1441\n",
      "Epoch: 2/10... Training loss: 0.1369\n",
      "Epoch: 2/10... Training loss: 0.1381\n",
      "Epoch: 2/10... Training loss: 0.1394\n",
      "Epoch: 2/10... Training loss: 0.1418\n",
      "Epoch: 2/10... Training loss: 0.1365\n",
      "Epoch: 2/10... Training loss: 0.1394\n",
      "Epoch: 2/10... Training loss: 0.1428\n",
      "Epoch: 2/10... Training loss: 0.1352\n",
      "Epoch: 2/10... Training loss: 0.1389\n",
      "Epoch: 2/10... Training loss: 0.1354\n",
      "Epoch: 2/10... Training loss: 0.1419\n",
      "Epoch: 2/10... Training loss: 0.1370\n",
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1369\n",
      "Epoch: 2/10... Training loss: 0.1430\n",
      "Epoch: 2/10... Training loss: 0.1434\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1386\n",
      "Epoch: 2/10... Training loss: 0.1374\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1384\n",
      "Epoch: 2/10... Training loss: 0.1433\n",
      "Epoch: 2/10... Training loss: 0.1409\n",
      "Epoch: 2/10... Training loss: 0.1384\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1466\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1322\n",
      "Epoch: 2/10... Training loss: 0.1287\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1358\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1374\n",
      "Epoch: 2/10... Training loss: 0.1330\n",
      "Epoch: 2/10... Training loss: 0.1353\n",
      "Epoch: 2/10... Training loss: 0.1466\n",
      "Epoch: 2/10... Training loss: 0.1371\n",
      "Epoch: 2/10... Training loss: 0.1388\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1364\n",
      "Epoch: 2/10... Training loss: 0.1397\n",
      "Epoch: 2/10... Training loss: 0.1393\n",
      "Epoch: 2/10... Training loss: 0.1422\n",
      "Epoch: 2/10... Training loss: 0.1434\n",
      "Epoch: 2/10... Training loss: 0.1388\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1396\n",
      "Epoch: 2/10... Training loss: 0.1420\n",
      "Epoch: 2/10... Training loss: 0.1359\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1313\n",
      "Epoch: 2/10... Training loss: 0.1404\n",
      "Epoch: 2/10... Training loss: 0.1420\n",
      "Epoch: 2/10... Training loss: 0.1350\n",
      "Epoch: 2/10... Training loss: 0.1415\n",
      "Epoch: 2/10... Training loss: 0.1343\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1411\n",
      "Epoch: 2/10... Training loss: 0.1436\n",
      "Epoch: 2/10... Training loss: 0.1359\n",
      "Epoch: 2/10... Training loss: 0.1427\n",
      "Epoch: 2/10... Training loss: 0.1346\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1379\n",
      "Epoch: 2/10... Training loss: 0.1387\n",
      "Epoch: 2/10... Training loss: 0.1412\n",
      "Epoch: 2/10... Training loss: 0.1355\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1449\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1324\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1340\n",
      "Epoch: 2/10... Training loss: 0.1383\n",
      "Epoch: 2/10... Training loss: 0.1366\n",
      "Epoch: 2/10... Training loss: 0.1384\n",
      "Epoch: 2/10... Training loss: 0.1347\n",
      "Epoch: 2/10... Training loss: 0.1341\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1337\n",
      "Epoch: 2/10... Training loss: 0.1379\n",
      "Epoch: 2/10... Training loss: 0.1329\n",
      "Epoch: 2/10... Training loss: 0.1376\n",
      "Epoch: 2/10... Training loss: 0.1373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10... Training loss: 0.1459\n",
      "Epoch: 2/10... Training loss: 0.1281\n",
      "Epoch: 2/10... Training loss: 0.1366\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1446\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1370\n",
      "Epoch: 2/10... Training loss: 0.1347\n",
      "Epoch: 2/10... Training loss: 0.1446\n",
      "Epoch: 2/10... Training loss: 0.1375\n",
      "Epoch: 2/10... Training loss: 0.1349\n",
      "Epoch: 2/10... Training loss: 0.1377\n",
      "Epoch: 2/10... Training loss: 0.1353\n",
      "Epoch: 2/10... Training loss: 0.1374\n",
      "Epoch: 2/10... Training loss: 0.1389\n",
      "Epoch: 2/10... Training loss: 0.1346\n",
      "Epoch: 2/10... Training loss: 0.1354\n",
      "Epoch: 2/10... Training loss: 0.1378\n",
      "Epoch: 2/10... Training loss: 0.1379\n",
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1367\n",
      "Epoch: 2/10... Training loss: 0.1348\n",
      "Epoch: 2/10... Training loss: 0.1342\n",
      "Epoch: 2/10... Training loss: 0.1342\n",
      "Epoch: 2/10... Training loss: 0.1419\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1366\n",
      "Epoch: 2/10... Training loss: 0.1387\n",
      "Epoch: 2/10... Training loss: 0.1320\n",
      "Epoch: 2/10... Training loss: 0.1397\n",
      "Epoch: 2/10... Training loss: 0.1415\n",
      "Epoch: 2/10... Training loss: 0.1381\n",
      "Epoch: 2/10... Training loss: 0.1394\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1330\n",
      "Epoch: 2/10... Training loss: 0.1374\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1310\n",
      "Epoch: 2/10... Training loss: 0.1460\n",
      "Epoch: 2/10... Training loss: 0.1353\n",
      "Epoch: 2/10... Training loss: 0.1399\n",
      "Epoch: 2/10... Training loss: 0.1391\n",
      "Epoch: 2/10... Training loss: 0.1407\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1344\n",
      "Epoch: 2/10... Training loss: 0.1343\n",
      "Epoch: 2/10... Training loss: 0.1399\n",
      "Epoch: 2/10... Training loss: 0.1375\n",
      "Epoch: 2/10... Training loss: 0.1353\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1317\n",
      "Epoch: 2/10... Training loss: 0.1310\n",
      "Epoch: 2/10... Training loss: 0.1327\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1320\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1425\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1388\n",
      "Epoch: 2/10... Training loss: 0.1421\n",
      "Epoch: 2/10... Training loss: 0.1354\n",
      "Epoch: 2/10... Training loss: 0.1403\n",
      "Epoch: 2/10... Training loss: 0.1416\n",
      "Epoch: 2/10... Training loss: 0.1399\n",
      "Epoch: 2/10... Training loss: 0.1391\n",
      "Epoch: 2/10... Training loss: 0.1395\n",
      "Epoch: 2/10... Training loss: 0.1429\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1357\n",
      "Epoch: 2/10... Training loss: 0.1378\n",
      "Epoch: 2/10... Training loss: 0.1370\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1335\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1330\n",
      "Epoch: 2/10... Training loss: 0.1390\n",
      "Epoch: 2/10... Training loss: 0.1319\n",
      "Epoch: 2/10... Training loss: 0.1357\n",
      "Epoch: 2/10... Training loss: 0.1365\n",
      "Epoch: 2/10... Training loss: 0.1342\n",
      "Epoch: 2/10... Training loss: 0.1444\n",
      "Epoch: 2/10... Training loss: 0.1345\n",
      "Epoch: 2/10... Training loss: 0.1365\n",
      "Epoch: 2/10... Training loss: 0.1411\n",
      "Epoch: 2/10... Training loss: 0.1331\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1382\n",
      "Epoch: 2/10... Training loss: 0.1283\n",
      "Epoch: 2/10... Training loss: 0.1382\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1383\n",
      "Epoch: 2/10... Training loss: 0.1298\n",
      "Epoch: 2/10... Training loss: 0.1337\n",
      "Epoch: 2/10... Training loss: 0.1273\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1424\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1376\n",
      "Epoch: 2/10... Training loss: 0.1348\n",
      "Epoch: 2/10... Training loss: 0.1373\n",
      "Epoch: 2/10... Training loss: 0.1369\n",
      "Epoch: 2/10... Training loss: 0.1241\n",
      "Epoch: 2/10... Training loss: 0.1331\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1281\n",
      "Epoch: 2/10... Training loss: 0.1337\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1403\n",
      "Epoch: 2/10... Training loss: 0.1322\n",
      "Epoch: 2/10... Training loss: 0.1316\n",
      "Epoch: 2/10... Training loss: 0.1327\n",
      "Epoch: 2/10... Training loss: 0.1302\n",
      "Epoch: 2/10... Training loss: 0.1272\n",
      "Epoch: 2/10... Training loss: 0.1401\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1319\n",
      "Epoch: 2/10... Training loss: 0.1415\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1242\n",
      "Epoch: 2/10... Training loss: 0.1302\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1337\n",
      "Epoch: 2/10... Training loss: 0.1295\n",
      "Epoch: 2/10... Training loss: 0.1375\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1402\n",
      "Epoch: 2/10... Training loss: 0.1271\n",
      "Epoch: 2/10... Training loss: 0.1351\n",
      "Epoch: 2/10... Training loss: 0.1315\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1356\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1373\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1302\n",
      "Epoch: 2/10... Training loss: 0.1290\n",
      "Epoch: 2/10... Training loss: 0.1414\n",
      "Epoch: 2/10... Training loss: 0.1303\n",
      "Epoch: 2/10... Training loss: 0.1319\n",
      "Epoch: 2/10... Training loss: 0.1320\n",
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1405\n",
      "Epoch: 2/10... Training loss: 0.1319\n",
      "Epoch: 2/10... Training loss: 0.1331\n",
      "Epoch: 2/10... Training loss: 0.1385\n",
      "Epoch: 2/10... Training loss: 0.1333\n",
      "Epoch: 2/10... Training loss: 0.1370\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1359\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1291\n",
      "Epoch: 2/10... Training loss: 0.1366\n",
      "Epoch: 2/10... Training loss: 0.1288\n",
      "Epoch: 2/10... Training loss: 0.1306\n",
      "Epoch: 2/10... Training loss: 0.1318\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1369\n",
      "Epoch: 2/10... Training loss: 0.1358\n",
      "Epoch: 2/10... Training loss: 0.1392\n",
      "Epoch: 2/10... Training loss: 0.1345\n",
      "Epoch: 2/10... Training loss: 0.1340\n",
      "Epoch: 2/10... Training loss: 0.1359\n",
      "Epoch: 2/10... Training loss: 0.1288\n",
      "Epoch: 2/10... Training loss: 0.1291\n",
      "Epoch: 2/10... Training loss: 0.1428\n",
      "Epoch: 2/10... Training loss: 0.1327\n",
      "Epoch: 2/10... Training loss: 0.1318\n",
      "Epoch: 2/10... Training loss: 0.1278\n",
      "Epoch: 2/10... Training loss: 0.1269\n",
      "Epoch: 2/10... Training loss: 0.1286\n",
      "Epoch: 2/10... Training loss: 0.1306\n",
      "Epoch: 2/10... Training loss: 0.1330\n",
      "Epoch: 2/10... Training loss: 0.1372\n",
      "Epoch: 2/10... Training loss: 0.1383\n",
      "Epoch: 2/10... Training loss: 0.1329\n",
      "Epoch: 2/10... Training loss: 0.1332\n",
      "Epoch: 2/10... Training loss: 0.1338\n",
      "Epoch: 2/10... Training loss: 0.1349\n",
      "Epoch: 2/10... Training loss: 0.1342\n",
      "Epoch: 2/10... Training loss: 0.1344\n",
      "Epoch: 2/10... Training loss: 0.1302\n",
      "Epoch: 2/10... Training loss: 0.1349\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1315\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1322\n",
      "Epoch: 2/10... Training loss: 0.1256\n",
      "Epoch: 2/10... Training loss: 0.1373\n",
      "Epoch: 2/10... Training loss: 0.1404\n",
      "Epoch: 2/10... Training loss: 0.1376\n",
      "Epoch: 2/10... Training loss: 0.1344\n",
      "Epoch: 2/10... Training loss: 0.1359\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1305\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1331\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1378\n",
      "Epoch: 2/10... Training loss: 0.1342\n",
      "Epoch: 2/10... Training loss: 0.1361\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1277\n",
      "Epoch: 2/10... Training loss: 0.1377\n",
      "Epoch: 2/10... Training loss: 0.1360\n",
      "Epoch: 2/10... Training loss: 0.1362\n",
      "Epoch: 2/10... Training loss: 0.1347\n",
      "Epoch: 2/10... Training loss: 0.1318\n",
      "Epoch: 2/10... Training loss: 0.1335\n",
      "Epoch: 2/10... Training loss: 0.1307\n",
      "Epoch: 2/10... Training loss: 0.1306\n",
      "Epoch: 2/10... Training loss: 0.1316\n",
      "Epoch: 2/10... Training loss: 0.1293\n",
      "Epoch: 2/10... Training loss: 0.1319\n",
      "Epoch: 2/10... Training loss: 0.1224\n",
      "Epoch: 2/10... Training loss: 0.1326\n",
      "Epoch: 2/10... Training loss: 0.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1322\n",
      "Epoch: 2/10... Training loss: 0.1363\n",
      "Epoch: 2/10... Training loss: 0.1301\n",
      "Epoch: 2/10... Training loss: 0.1352\n",
      "Epoch: 2/10... Training loss: 0.1306\n",
      "Epoch: 2/10... Training loss: 0.1312\n",
      "Epoch: 2/10... Training loss: 0.1243\n",
      "Epoch: 2/10... Training loss: 0.1348\n",
      "Epoch: 2/10... Training loss: 0.1337\n",
      "Epoch: 2/10... Training loss: 0.1348\n",
      "Epoch: 2/10... Training loss: 0.1390\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1292\n",
      "Epoch: 2/10... Training loss: 0.1280\n",
      "Epoch: 2/10... Training loss: 0.1352\n",
      "Epoch: 2/10... Training loss: 0.1244\n",
      "Epoch: 2/10... Training loss: 0.1303\n",
      "Epoch: 2/10... Training loss: 0.1317\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1270\n",
      "Epoch: 2/10... Training loss: 0.1269\n",
      "Epoch: 2/10... Training loss: 0.1286\n",
      "Epoch: 2/10... Training loss: 0.1326\n",
      "Epoch: 2/10... Training loss: 0.1312\n",
      "Epoch: 2/10... Training loss: 0.1310\n",
      "Epoch: 2/10... Training loss: 0.1260\n",
      "Epoch: 2/10... Training loss: 0.1274\n",
      "Epoch: 2/10... Training loss: 0.1251\n",
      "Epoch: 2/10... Training loss: 0.1297\n",
      "Epoch: 2/10... Training loss: 0.1375\n",
      "Epoch: 2/10... Training loss: 0.1379\n",
      "Epoch: 2/10... Training loss: 0.1341\n",
      "Epoch: 2/10... Training loss: 0.1347\n",
      "Epoch: 2/10... Training loss: 0.1349\n",
      "Epoch: 2/10... Training loss: 0.1323\n",
      "Epoch: 2/10... Training loss: 0.1258\n",
      "Epoch: 2/10... Training loss: 0.1312\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1258\n",
      "Epoch: 2/10... Training loss: 0.1256\n",
      "Epoch: 2/10... Training loss: 0.1301\n",
      "Epoch: 2/10... Training loss: 0.1259\n",
      "Epoch: 2/10... Training loss: 0.1306\n",
      "Epoch: 2/10... Training loss: 0.1269\n",
      "Epoch: 2/10... Training loss: 0.1294\n",
      "Epoch: 2/10... Training loss: 0.1315\n",
      "Epoch: 2/10... Training loss: 0.1334\n",
      "Epoch: 2/10... Training loss: 0.1321\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1302\n",
      "Epoch: 2/10... Training loss: 0.1331\n",
      "Epoch: 2/10... Training loss: 0.1327\n",
      "Epoch: 2/10... Training loss: 0.1287\n",
      "Epoch: 2/10... Training loss: 0.1305\n",
      "Epoch: 2/10... Training loss: 0.1357\n",
      "Epoch: 2/10... Training loss: 0.1356\n",
      "Epoch: 2/10... Training loss: 0.1275\n",
      "Epoch: 2/10... Training loss: 0.1356\n",
      "Epoch: 2/10... Training loss: 0.1304\n",
      "Epoch: 2/10... Training loss: 0.1317\n",
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1310\n",
      "Epoch: 2/10... Training loss: 0.1280\n",
      "Epoch: 2/10... Training loss: 0.1276\n",
      "Epoch: 2/10... Training loss: 0.1325\n",
      "Epoch: 2/10... Training loss: 0.1291\n",
      "Epoch: 2/10... Training loss: 0.1309\n",
      "Epoch: 2/10... Training loss: 0.1282\n",
      "Epoch: 2/10... Training loss: 0.1320\n",
      "Epoch: 2/10... Training loss: 0.1263\n",
      "Epoch: 2/10... Training loss: 0.1313\n",
      "Epoch: 2/10... Training loss: 0.1280\n",
      "Epoch: 2/10... Training loss: 0.1313\n",
      "Epoch: 2/10... Training loss: 0.1267\n",
      "Epoch: 2/10... Training loss: 0.1268\n",
      "Epoch: 2/10... Training loss: 0.1292\n",
      "Epoch: 2/10... Training loss: 0.1328\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1317\n",
      "Epoch: 2/10... Training loss: 0.1256\n",
      "Epoch: 2/10... Training loss: 0.1282\n",
      "Epoch: 2/10... Training loss: 0.1276\n",
      "Epoch: 2/10... Training loss: 0.1334\n",
      "Epoch: 2/10... Training loss: 0.1283\n",
      "Epoch: 2/10... Training loss: 0.1368\n",
      "Epoch: 2/10... Training loss: 0.1279\n",
      "Epoch: 2/10... Training loss: 0.1324\n",
      "Epoch: 2/10... Training loss: 0.1336\n",
      "Epoch: 2/10... Training loss: 0.1284\n",
      "Epoch: 3/10... Training loss: 0.1292\n",
      "Epoch: 3/10... Training loss: 0.1277\n",
      "Epoch: 3/10... Training loss: 0.1342\n",
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1305\n",
      "Epoch: 3/10... Training loss: 0.1346\n",
      "Epoch: 3/10... Training loss: 0.1361\n",
      "Epoch: 3/10... Training loss: 0.1354\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1323\n",
      "Epoch: 3/10... Training loss: 0.1305\n",
      "Epoch: 3/10... Training loss: 0.1298\n",
      "Epoch: 3/10... Training loss: 0.1302\n",
      "Epoch: 3/10... Training loss: 0.1402\n",
      "Epoch: 3/10... Training loss: 0.1324\n",
      "Epoch: 3/10... Training loss: 0.1374\n",
      "Epoch: 3/10... Training loss: 0.1319\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1291\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1310\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1385\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1312\n",
      "Epoch: 3/10... Training loss: 0.1353\n",
      "Epoch: 3/10... Training loss: 0.1312\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1343\n",
      "Epoch: 3/10... Training loss: 0.1292\n",
      "Epoch: 3/10... Training loss: 0.1361\n",
      "Epoch: 3/10... Training loss: 0.1316\n",
      "Epoch: 3/10... Training loss: 0.1292\n",
      "Epoch: 3/10... Training loss: 0.1291\n",
      "Epoch: 3/10... Training loss: 0.1226\n",
      "Epoch: 3/10... Training loss: 0.1314\n",
      "Epoch: 3/10... Training loss: 0.1371\n",
      "Epoch: 3/10... Training loss: 0.1332\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1302\n",
      "Epoch: 3/10... Training loss: 0.1366\n",
      "Epoch: 3/10... Training loss: 0.1355\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1296\n",
      "Epoch: 3/10... Training loss: 0.1194\n",
      "Epoch: 3/10... Training loss: 0.1330\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1327\n",
      "Epoch: 3/10... Training loss: 0.1302\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1371\n",
      "Epoch: 3/10... Training loss: 0.1319\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1404\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1330\n",
      "Epoch: 3/10... Training loss: 0.1378\n",
      "Epoch: 3/10... Training loss: 0.1315\n",
      "Epoch: 3/10... Training loss: 0.1254\n",
      "Epoch: 3/10... Training loss: 0.1333\n",
      "Epoch: 3/10... Training loss: 0.1350\n",
      "Epoch: 3/10... Training loss: 0.1306\n",
      "Epoch: 3/10... Training loss: 0.1381\n",
      "Epoch: 3/10... Training loss: 0.1242\n",
      "Epoch: 3/10... Training loss: 0.1327\n",
      "Epoch: 3/10... Training loss: 0.1292\n",
      "Epoch: 3/10... Training loss: 0.1277\n",
      "Epoch: 3/10... Training loss: 0.1313\n",
      "Epoch: 3/10... Training loss: 0.1317\n",
      "Epoch: 3/10... Training loss: 0.1281\n",
      "Epoch: 3/10... Training loss: 0.1193\n",
      "Epoch: 3/10... Training loss: 0.1212\n",
      "Epoch: 3/10... Training loss: 0.1323\n",
      "Epoch: 3/10... Training loss: 0.1275\n",
      "Epoch: 3/10... Training loss: 0.1333\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1336\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1305\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1320\n",
      "Epoch: 3/10... Training loss: 0.1300\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1312\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1300\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1376\n",
      "Epoch: 3/10... Training loss: 0.1277\n",
      "Epoch: 3/10... Training loss: 0.1332\n",
      "Epoch: 3/10... Training loss: 0.1344\n",
      "Epoch: 3/10... Training loss: 0.1322\n",
      "Epoch: 3/10... Training loss: 0.1333\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1300\n",
      "Epoch: 3/10... Training loss: 0.1289\n",
      "Epoch: 3/10... Training loss: 0.1331\n",
      "Epoch: 3/10... Training loss: 0.1294\n",
      "Epoch: 3/10... Training loss: 0.1437\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1361\n",
      "Epoch: 3/10... Training loss: 0.1259\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1282\n",
      "Epoch: 3/10... Training loss: 0.1313\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1308\n",
      "Epoch: 3/10... Training loss: 0.1182\n",
      "Epoch: 3/10... Training loss: 0.1293\n",
      "Epoch: 3/10... Training loss: 0.1327\n",
      "Epoch: 3/10... Training loss: 0.1242\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1217\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1262\n",
      "Epoch: 3/10... Training loss: 0.1308\n",
      "Epoch: 3/10... Training loss: 0.1314\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1320\n",
      "Epoch: 3/10... Training loss: 0.1281\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10... Training loss: 0.1291\n",
      "Epoch: 3/10... Training loss: 0.1252\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1250\n",
      "Epoch: 3/10... Training loss: 0.1317\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1196\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1248\n",
      "Epoch: 3/10... Training loss: 0.1223\n",
      "Epoch: 3/10... Training loss: 0.1332\n",
      "Epoch: 3/10... Training loss: 0.1332\n",
      "Epoch: 3/10... Training loss: 0.1305\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1224\n",
      "Epoch: 3/10... Training loss: 0.1312\n",
      "Epoch: 3/10... Training loss: 0.1299\n",
      "Epoch: 3/10... Training loss: 0.1213\n",
      "Epoch: 3/10... Training loss: 0.1252\n",
      "Epoch: 3/10... Training loss: 0.1270\n",
      "Epoch: 3/10... Training loss: 0.1300\n",
      "Epoch: 3/10... Training loss: 0.1335\n",
      "Epoch: 3/10... Training loss: 0.1258\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1325\n",
      "Epoch: 3/10... Training loss: 0.1312\n",
      "Epoch: 3/10... Training loss: 0.1322\n",
      "Epoch: 3/10... Training loss: 0.1356\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1281\n",
      "Epoch: 3/10... Training loss: 0.1277\n",
      "Epoch: 3/10... Training loss: 0.1325\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1332\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1344\n",
      "Epoch: 3/10... Training loss: 0.1295\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1174\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1366\n",
      "Epoch: 3/10... Training loss: 0.1186\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1277\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1265\n",
      "Epoch: 3/10... Training loss: 0.1279\n",
      "Epoch: 3/10... Training loss: 0.1259\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1257\n",
      "Epoch: 3/10... Training loss: 0.1257\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1254\n",
      "Epoch: 3/10... Training loss: 0.1271\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1352\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1315\n",
      "Epoch: 3/10... Training loss: 0.1250\n",
      "Epoch: 3/10... Training loss: 0.1259\n",
      "Epoch: 3/10... Training loss: 0.1276\n",
      "Epoch: 3/10... Training loss: 0.1246\n",
      "Epoch: 3/10... Training loss: 0.1335\n",
      "Epoch: 3/10... Training loss: 0.1276\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1358\n",
      "Epoch: 3/10... Training loss: 0.1328\n",
      "Epoch: 3/10... Training loss: 0.1286\n",
      "Epoch: 3/10... Training loss: 0.1239\n",
      "Epoch: 3/10... Training loss: 0.1255\n",
      "Epoch: 3/10... Training loss: 0.1292\n",
      "Epoch: 3/10... Training loss: 0.1244\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1317\n",
      "Epoch: 3/10... Training loss: 0.1340\n",
      "Epoch: 3/10... Training loss: 0.1308\n",
      "Epoch: 3/10... Training loss: 0.1315\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1316\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1295\n",
      "Epoch: 3/10... Training loss: 0.1272\n",
      "Epoch: 3/10... Training loss: 0.1269\n",
      "Epoch: 3/10... Training loss: 0.1248\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1287\n",
      "Epoch: 3/10... Training loss: 0.1257\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1243\n",
      "Epoch: 3/10... Training loss: 0.1265\n",
      "Epoch: 3/10... Training loss: 0.1300\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1265\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1258\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1282\n",
      "Epoch: 3/10... Training loss: 0.1275\n",
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1321\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1202\n",
      "Epoch: 3/10... Training loss: 0.1248\n",
      "Epoch: 3/10... Training loss: 0.1323\n",
      "Epoch: 3/10... Training loss: 0.1208\n",
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1298\n",
      "Epoch: 3/10... Training loss: 0.1313\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1289\n",
      "Epoch: 3/10... Training loss: 0.1291\n",
      "Epoch: 3/10... Training loss: 0.1242\n",
      "Epoch: 3/10... Training loss: 0.1313\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1206\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1289\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1258\n",
      "Epoch: 3/10... Training loss: 0.1269\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1343\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1210\n",
      "Epoch: 3/10... Training loss: 0.1214\n",
      "Epoch: 3/10... Training loss: 0.1324\n",
      "Epoch: 3/10... Training loss: 0.1228\n",
      "Epoch: 3/10... Training loss: 0.1220\n",
      "Epoch: 3/10... Training loss: 0.1207\n",
      "Epoch: 3/10... Training loss: 0.1288\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1296\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1195\n",
      "Epoch: 3/10... Training loss: 0.1233\n",
      "Epoch: 3/10... Training loss: 0.1247\n",
      "Epoch: 3/10... Training loss: 0.1275\n",
      "Epoch: 3/10... Training loss: 0.1306\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1219\n",
      "Epoch: 3/10... Training loss: 0.1213\n",
      "Epoch: 3/10... Training loss: 0.1212\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1227\n",
      "Epoch: 3/10... Training loss: 0.1296\n",
      "Epoch: 3/10... Training loss: 0.1254\n",
      "Epoch: 3/10... Training loss: 0.1297\n",
      "Epoch: 3/10... Training loss: 0.1296\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1257\n",
      "Epoch: 3/10... Training loss: 0.1183\n",
      "Epoch: 3/10... Training loss: 0.1211\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1316\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1244\n",
      "Epoch: 3/10... Training loss: 0.1213\n",
      "Epoch: 3/10... Training loss: 0.1205\n",
      "Epoch: 3/10... Training loss: 0.1283\n",
      "Epoch: 3/10... Training loss: 0.1146\n",
      "Epoch: 3/10... Training loss: 0.1346\n",
      "Epoch: 3/10... Training loss: 0.1210\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1228\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1217\n",
      "Epoch: 3/10... Training loss: 0.1228\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1299\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1329\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1291\n",
      "Epoch: 3/10... Training loss: 0.1262\n",
      "Epoch: 3/10... Training loss: 0.1267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1242\n",
      "Epoch: 3/10... Training loss: 0.1228\n",
      "Epoch: 3/10... Training loss: 0.1307\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1223\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1324\n",
      "Epoch: 3/10... Training loss: 0.1326\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1295\n",
      "Epoch: 3/10... Training loss: 0.1262\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1304\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1218\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1256\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1223\n",
      "Epoch: 3/10... Training loss: 0.1196\n",
      "Epoch: 3/10... Training loss: 0.1273\n",
      "Epoch: 3/10... Training loss: 0.1257\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1203\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1298\n",
      "Epoch: 3/10... Training loss: 0.1242\n",
      "Epoch: 3/10... Training loss: 0.1270\n",
      "Epoch: 3/10... Training loss: 0.1273\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1198\n",
      "Epoch: 3/10... Training loss: 0.1217\n",
      "Epoch: 3/10... Training loss: 0.1254\n",
      "Epoch: 3/10... Training loss: 0.1298\n",
      "Epoch: 3/10... Training loss: 0.1171\n",
      "Epoch: 3/10... Training loss: 0.1288\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1189\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1293\n",
      "Epoch: 3/10... Training loss: 0.1282\n",
      "Epoch: 3/10... Training loss: 0.1276\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1196\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1239\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1262\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1243\n",
      "Epoch: 3/10... Training loss: 0.1204\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1204\n",
      "Epoch: 3/10... Training loss: 0.1276\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1212\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1247\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1219\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1208\n",
      "Epoch: 3/10... Training loss: 0.1207\n",
      "Epoch: 3/10... Training loss: 0.1310\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1250\n",
      "Epoch: 3/10... Training loss: 0.1290\n",
      "Epoch: 3/10... Training loss: 0.1237\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1219\n",
      "Epoch: 3/10... Training loss: 0.1212\n",
      "Epoch: 3/10... Training loss: 0.1178\n",
      "Epoch: 3/10... Training loss: 0.1217\n",
      "Epoch: 3/10... Training loss: 0.1205\n",
      "Epoch: 3/10... Training loss: 0.1271\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1334\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1233\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1255\n",
      "Epoch: 3/10... Training loss: 0.1303\n",
      "Epoch: 3/10... Training loss: 0.1248\n",
      "Epoch: 3/10... Training loss: 0.1229\n",
      "Epoch: 3/10... Training loss: 0.1223\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1271\n",
      "Epoch: 3/10... Training loss: 0.1189\n",
      "Epoch: 3/10... Training loss: 0.1313\n",
      "Epoch: 3/10... Training loss: 0.1184\n",
      "Epoch: 3/10... Training loss: 0.1259\n",
      "Epoch: 3/10... Training loss: 0.1243\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1224\n",
      "Epoch: 3/10... Training loss: 0.1236\n",
      "Epoch: 3/10... Training loss: 0.1208\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1205\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1224\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1213\n",
      "Epoch: 3/10... Training loss: 0.1281\n",
      "Epoch: 3/10... Training loss: 0.1294\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1214\n",
      "Epoch: 3/10... Training loss: 0.1302\n",
      "Epoch: 3/10... Training loss: 0.1227\n",
      "Epoch: 3/10... Training loss: 0.1302\n",
      "Epoch: 3/10... Training loss: 0.1265\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1211\n",
      "Epoch: 3/10... Training loss: 0.1286\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1273\n",
      "Epoch: 3/10... Training loss: 0.1240\n",
      "Epoch: 3/10... Training loss: 0.1330\n",
      "Epoch: 3/10... Training loss: 0.1195\n",
      "Epoch: 3/10... Training loss: 0.1206\n",
      "Epoch: 3/10... Training loss: 0.1299\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1206\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1270\n",
      "Epoch: 3/10... Training loss: 0.1198\n",
      "Epoch: 3/10... Training loss: 0.1244\n",
      "Epoch: 3/10... Training loss: 0.1246\n",
      "Epoch: 3/10... Training loss: 0.1278\n",
      "Epoch: 3/10... Training loss: 0.1233\n",
      "Epoch: 3/10... Training loss: 0.1266\n",
      "Epoch: 3/10... Training loss: 0.1206\n",
      "Epoch: 3/10... Training loss: 0.1187\n",
      "Epoch: 3/10... Training loss: 0.1314\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1175\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1224\n",
      "Epoch: 3/10... Training loss: 0.1294\n",
      "Epoch: 3/10... Training loss: 0.1211\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1270\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1280\n",
      "Epoch: 3/10... Training loss: 0.1246\n",
      "Epoch: 3/10... Training loss: 0.1235\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1230\n",
      "Epoch: 3/10... Training loss: 0.1238\n",
      "Epoch: 3/10... Training loss: 0.1274\n",
      "Epoch: 3/10... Training loss: 0.1264\n",
      "Epoch: 3/10... Training loss: 0.1262\n",
      "Epoch: 3/10... Training loss: 0.1282\n",
      "Epoch: 3/10... Training loss: 0.1145\n",
      "Epoch: 3/10... Training loss: 0.1245\n",
      "Epoch: 3/10... Training loss: 0.1182\n",
      "Epoch: 3/10... Training loss: 0.1322\n",
      "Epoch: 3/10... Training loss: 0.1247\n",
      "Epoch: 3/10... Training loss: 0.1275\n",
      "Epoch: 3/10... Training loss: 0.1221\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1234\n",
      "Epoch: 3/10... Training loss: 0.1217\n",
      "Epoch: 3/10... Training loss: 0.1231\n",
      "Epoch: 3/10... Training loss: 0.1195\n",
      "Epoch: 3/10... Training loss: 0.1289\n",
      "Epoch: 3/10... Training loss: 0.1216\n",
      "Epoch: 3/10... Training loss: 0.1244\n",
      "Epoch: 3/10... Training loss: 0.1267\n",
      "Epoch: 3/10... Training loss: 0.1199\n",
      "Epoch: 3/10... Training loss: 0.1173\n",
      "Epoch: 3/10... Training loss: 0.1282\n",
      "Epoch: 3/10... Training loss: 0.1225\n",
      "Epoch: 3/10... Training loss: 0.1241\n",
      "Epoch: 3/10... Training loss: 0.1285\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1201\n",
      "Epoch: 3/10... Training loss: 0.1189\n",
      "Epoch: 3/10... Training loss: 0.1298\n",
      "Epoch: 3/10... Training loss: 0.1191\n",
      "Epoch: 3/10... Training loss: 0.1179\n",
      "Epoch: 3/10... Training loss: 0.1314\n",
      "Epoch: 3/10... Training loss: 0.1207\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1268\n",
      "Epoch: 3/10... Training loss: 0.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10... Training loss: 0.1223\n",
      "Epoch: 3/10... Training loss: 0.1287\n",
      "Epoch: 3/10... Training loss: 0.1260\n",
      "Epoch: 3/10... Training loss: 0.1168\n",
      "Epoch: 3/10... Training loss: 0.1186\n",
      "Epoch: 3/10... Training loss: 0.1224\n",
      "Epoch: 3/10... Training loss: 0.1261\n",
      "Epoch: 3/10... Training loss: 0.1192\n",
      "Epoch: 3/10... Training loss: 0.1176\n",
      "Epoch: 3/10... Training loss: 0.1259\n",
      "Epoch: 3/10... Training loss: 0.1249\n",
      "Epoch: 3/10... Training loss: 0.1186\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1232\n",
      "Epoch: 3/10... Training loss: 0.1301\n",
      "Epoch: 3/10... Training loss: 0.1230\n",
      "Epoch: 3/10... Training loss: 0.1189\n",
      "Epoch: 3/10... Training loss: 0.1155\n",
      "Epoch: 3/10... Training loss: 0.1251\n",
      "Epoch: 3/10... Training loss: 0.1272\n",
      "Epoch: 3/10... Training loss: 0.1222\n",
      "Epoch: 3/10... Training loss: 0.1174\n",
      "Epoch: 3/10... Training loss: 0.1215\n",
      "Epoch: 3/10... Training loss: 0.1253\n",
      "Epoch: 4/10... Training loss: 0.1267\n",
      "Epoch: 4/10... Training loss: 0.1274\n",
      "Epoch: 4/10... Training loss: 0.1246\n",
      "Epoch: 4/10... Training loss: 0.1254\n",
      "Epoch: 4/10... Training loss: 0.1260\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1119\n",
      "Epoch: 4/10... Training loss: 0.1175\n",
      "Epoch: 4/10... Training loss: 0.1250\n",
      "Epoch: 4/10... Training loss: 0.1234\n",
      "Epoch: 4/10... Training loss: 0.1234\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1287\n",
      "Epoch: 4/10... Training loss: 0.1250\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1290\n",
      "Epoch: 4/10... Training loss: 0.1269\n",
      "Epoch: 4/10... Training loss: 0.1177\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1272\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1142\n",
      "Epoch: 4/10... Training loss: 0.1241\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1225\n",
      "Epoch: 4/10... Training loss: 0.1273\n",
      "Epoch: 4/10... Training loss: 0.1215\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1215\n",
      "Epoch: 4/10... Training loss: 0.1221\n",
      "Epoch: 4/10... Training loss: 0.1292\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1194\n",
      "Epoch: 4/10... Training loss: 0.1274\n",
      "Epoch: 4/10... Training loss: 0.1302\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1171\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1261\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1277\n",
      "Epoch: 4/10... Training loss: 0.1227\n",
      "Epoch: 4/10... Training loss: 0.1297\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1277\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1264\n",
      "Epoch: 4/10... Training loss: 0.1162\n",
      "Epoch: 4/10... Training loss: 0.1257\n",
      "Epoch: 4/10... Training loss: 0.1140\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1262\n",
      "Epoch: 4/10... Training loss: 0.1328\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1228\n",
      "Epoch: 4/10... Training loss: 0.1244\n",
      "Epoch: 4/10... Training loss: 0.1275\n",
      "Epoch: 4/10... Training loss: 0.1209\n",
      "Epoch: 4/10... Training loss: 0.1285\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1239\n",
      "Epoch: 4/10... Training loss: 0.1252\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1244\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1290\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1265\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1248\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1228\n",
      "Epoch: 4/10... Training loss: 0.1303\n",
      "Epoch: 4/10... Training loss: 0.1256\n",
      "Epoch: 4/10... Training loss: 0.1221\n",
      "Epoch: 4/10... Training loss: 0.1262\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1264\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1267\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1254\n",
      "Epoch: 4/10... Training loss: 0.1249\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1251\n",
      "Epoch: 4/10... Training loss: 0.1189\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1260\n",
      "Epoch: 4/10... Training loss: 0.1273\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1186\n",
      "Epoch: 4/10... Training loss: 0.1168\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1166\n",
      "Epoch: 4/10... Training loss: 0.1271\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1270\n",
      "Epoch: 4/10... Training loss: 0.1219\n",
      "Epoch: 4/10... Training loss: 0.1167\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1264\n",
      "Epoch: 4/10... Training loss: 0.1261\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1189\n",
      "Epoch: 4/10... Training loss: 0.1269\n",
      "Epoch: 4/10... Training loss: 0.1232\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1248\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1261\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1134\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1220\n",
      "Epoch: 4/10... Training loss: 0.1246\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1194\n",
      "Epoch: 4/10... Training loss: 0.1251\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1181\n",
      "Epoch: 4/10... Training loss: 0.1140\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1267\n",
      "Epoch: 4/10... Training loss: 0.1193\n",
      "Epoch: 4/10... Training loss: 0.1209\n",
      "Epoch: 4/10... Training loss: 0.1188\n",
      "Epoch: 4/10... Training loss: 0.1233\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1149\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1181\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1278\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1251\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1272\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10... Training loss: 0.1179\n",
      "Epoch: 4/10... Training loss: 0.1254\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1225\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1166\n",
      "Epoch: 4/10... Training loss: 0.1215\n",
      "Epoch: 4/10... Training loss: 0.1258\n",
      "Epoch: 4/10... Training loss: 0.1223\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1241\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1114\n",
      "Epoch: 4/10... Training loss: 0.1230\n",
      "Epoch: 4/10... Training loss: 0.1125\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1188\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1251\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1219\n",
      "Epoch: 4/10... Training loss: 0.1169\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1245\n",
      "Epoch: 4/10... Training loss: 0.1162\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1162\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1181\n",
      "Epoch: 4/10... Training loss: 0.1291\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1239\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1247\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1232\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1228\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1250\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1223\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1171\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1260\n",
      "Epoch: 4/10... Training loss: 0.1247\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1233\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1245\n",
      "Epoch: 4/10... Training loss: 0.1259\n",
      "Epoch: 4/10... Training loss: 0.1137\n",
      "Epoch: 4/10... Training loss: 0.1236\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1177\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1168\n",
      "Epoch: 4/10... Training loss: 0.1270\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1166\n",
      "Epoch: 4/10... Training loss: 0.1157\n",
      "Epoch: 4/10... Training loss: 0.1167\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1145\n",
      "Epoch: 4/10... Training loss: 0.1167\n",
      "Epoch: 4/10... Training loss: 0.1164\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1234\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1193\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1220\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1171\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1181\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1253\n",
      "Epoch: 4/10... Training loss: 0.1236\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1228\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1163\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1169\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1109\n",
      "Epoch: 4/10... Training loss: 0.1163\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1223\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1165\n",
      "Epoch: 4/10... Training loss: 0.1164\n",
      "Epoch: 4/10... Training loss: 0.1161\n",
      "Epoch: 4/10... Training loss: 0.1152\n",
      "Epoch: 4/10... Training loss: 0.1105\n",
      "Epoch: 4/10... Training loss: 0.1168\n",
      "Epoch: 4/10... Training loss: 0.1220\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1244\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1243\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1223\n",
      "Epoch: 4/10... Training loss: 0.1194\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1080\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1221\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1238\n",
      "Epoch: 4/10... Training loss: 0.1225\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1254\n",
      "Epoch: 4/10... Training loss: 0.1224\n",
      "Epoch: 4/10... Training loss: 0.1263\n",
      "Epoch: 4/10... Training loss: 0.1234\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1214\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1170\n",
      "Epoch: 4/10... Training loss: 0.1234\n",
      "Epoch: 4/10... Training loss: 0.1141\n",
      "Epoch: 4/10... Training loss: 0.1175\n",
      "Epoch: 4/10... Training loss: 0.1174\n",
      "Epoch: 4/10... Training loss: 0.1144\n",
      "Epoch: 4/10... Training loss: 0.1181\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1175\n",
      "Epoch: 4/10... Training loss: 0.1245\n",
      "Epoch: 4/10... Training loss: 0.1241\n",
      "Epoch: 4/10... Training loss: 0.1137\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1150\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1189\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1232\n",
      "Epoch: 4/10... Training loss: 0.1162\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1242\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1225\n",
      "Epoch: 4/10... Training loss: 0.1161\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1236\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1235\n",
      "Epoch: 4/10... Training loss: 0.1172\n",
      "Epoch: 4/10... Training loss: 0.1233\n",
      "Epoch: 4/10... Training loss: 0.1199\n",
      "Epoch: 4/10... Training loss: 0.1152\n",
      "Epoch: 4/10... Training loss: 0.1156\n",
      "Epoch: 4/10... Training loss: 0.1202\n",
      "Epoch: 4/10... Training loss: 0.1174\n",
      "Epoch: 4/10... Training loss: 0.1150\n",
      "Epoch: 4/10... Training loss: 0.1147\n",
      "Epoch: 4/10... Training loss: 0.1150\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1160\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1167\n",
      "Epoch: 4/10... Training loss: 0.1148\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1164\n",
      "Epoch: 4/10... Training loss: 0.1170\n",
      "Epoch: 4/10... Training loss: 0.1160\n",
      "Epoch: 4/10... Training loss: 0.1201\n",
      "Epoch: 4/10... Training loss: 0.1219\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1218\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1166\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1182\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1149\n",
      "Epoch: 4/10... Training loss: 0.1180\n",
      "Epoch: 4/10... Training loss: 0.1171\n",
      "Epoch: 4/10... Training loss: 0.1236\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1151\n",
      "Epoch: 4/10... Training loss: 0.1130\n",
      "Epoch: 4/10... Training loss: 0.1204\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1157\n",
      "Epoch: 4/10... Training loss: 0.1155\n",
      "Epoch: 4/10... Training loss: 0.1172\n",
      "Epoch: 4/10... Training loss: 0.1265\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1262\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1195\n",
      "Epoch: 4/10... Training loss: 0.1213\n",
      "Epoch: 4/10... Training loss: 0.1177\n",
      "Epoch: 4/10... Training loss: 0.1155\n",
      "Epoch: 4/10... Training loss: 0.1193\n",
      "Epoch: 4/10... Training loss: 0.1161\n",
      "Epoch: 4/10... Training loss: 0.1203\n",
      "Epoch: 4/10... Training loss: 0.1210\n",
      "Epoch: 4/10... Training loss: 0.1255\n",
      "Epoch: 4/10... Training loss: 0.1194\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1221\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1289\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1169\n",
      "Epoch: 4/10... Training loss: 0.1200\n",
      "Epoch: 4/10... Training loss: 0.1169\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1170\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1226\n",
      "Epoch: 4/10... Training loss: 0.1174\n",
      "Epoch: 4/10... Training loss: 0.1212\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1199\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1208\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1215\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1127\n",
      "Epoch: 4/10... Training loss: 0.1220\n",
      "Epoch: 4/10... Training loss: 0.1216\n",
      "Epoch: 4/10... Training loss: 0.1220\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1199\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1207\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1233\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1215\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1176\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1158\n",
      "Epoch: 4/10... Training loss: 0.1189\n",
      "Epoch: 4/10... Training loss: 0.1211\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1163\n",
      "Epoch: 4/10... Training loss: 0.1150\n",
      "Epoch: 4/10... Training loss: 0.1133\n",
      "Epoch: 4/10... Training loss: 0.1115\n",
      "Epoch: 4/10... Training loss: 0.1159\n",
      "Epoch: 4/10... Training loss: 0.1194\n",
      "Epoch: 4/10... Training loss: 0.1190\n",
      "Epoch: 4/10... Training loss: 0.1165\n",
      "Epoch: 4/10... Training loss: 0.1237\n",
      "Epoch: 4/10... Training loss: 0.1228\n",
      "Epoch: 4/10... Training loss: 0.1187\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1166\n",
      "Epoch: 4/10... Training loss: 0.1222\n",
      "Epoch: 4/10... Training loss: 0.1146\n",
      "Epoch: 4/10... Training loss: 0.1191\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1184\n",
      "Epoch: 4/10... Training loss: 0.1186\n",
      "Epoch: 4/10... Training loss: 0.1169\n",
      "Epoch: 4/10... Training loss: 0.1206\n",
      "Epoch: 4/10... Training loss: 0.1231\n",
      "Epoch: 4/10... Training loss: 0.1161\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1221\n",
      "Epoch: 4/10... Training loss: 0.1172\n",
      "Epoch: 4/10... Training loss: 0.1156\n",
      "Epoch: 4/10... Training loss: 0.1178\n",
      "Epoch: 4/10... Training loss: 0.1196\n",
      "Epoch: 4/10... Training loss: 0.1199\n",
      "Epoch: 4/10... Training loss: 0.1168\n",
      "Epoch: 4/10... Training loss: 0.1217\n",
      "Epoch: 4/10... Training loss: 0.1139\n",
      "Epoch: 4/10... Training loss: 0.1160\n",
      "Epoch: 4/10... Training loss: 0.1198\n",
      "Epoch: 4/10... Training loss: 0.1229\n",
      "Epoch: 4/10... Training loss: 0.1260\n",
      "Epoch: 4/10... Training loss: 0.1173\n",
      "Epoch: 4/10... Training loss: 0.1240\n",
      "Epoch: 4/10... Training loss: 0.1219\n",
      "Epoch: 4/10... Training loss: 0.1197\n",
      "Epoch: 4/10... Training loss: 0.1168\n",
      "Epoch: 4/10... Training loss: 0.1149\n",
      "Epoch: 4/10... Training loss: 0.1188\n",
      "Epoch: 4/10... Training loss: 0.1205\n",
      "Epoch: 4/10... Training loss: 0.1177\n",
      "Epoch: 4/10... Training loss: 0.1185\n",
      "Epoch: 4/10... Training loss: 0.1183\n",
      "Epoch: 4/10... Training loss: 0.1192\n",
      "Epoch: 4/10... Training loss: 0.1248\n",
      "Epoch: 5/10... Training loss: 0.1134\n",
      "Epoch: 5/10... Training loss: 0.1208\n",
      "Epoch: 5/10... Training loss: 0.1204\n",
      "Epoch: 5/10... Training loss: 0.1195\n",
      "Epoch: 5/10... Training loss: 0.1134\n",
      "Epoch: 5/10... Training loss: 0.1181\n",
      "Epoch: 5/10... Training loss: 0.1214\n",
      "Epoch: 5/10... Training loss: 0.1199\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1200\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1192\n",
      "Epoch: 5/10... Training loss: 0.1246\n",
      "Epoch: 5/10... Training loss: 0.1195\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1184\n",
      "Epoch: 5/10... Training loss: 0.1266\n",
      "Epoch: 5/10... Training loss: 0.1184\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1185\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1127\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1125\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1181\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1204\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1163\n",
      "Epoch: 5/10... Training loss: 0.1196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10... Training loss: 0.1100\n",
      "Epoch: 5/10... Training loss: 0.1205\n",
      "Epoch: 5/10... Training loss: 0.1157\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1247\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1155\n",
      "Epoch: 5/10... Training loss: 0.1234\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1268\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1251\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1209\n",
      "Epoch: 5/10... Training loss: 0.1217\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1224\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1062\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1229\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1203\n",
      "Epoch: 5/10... Training loss: 0.1224\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1194\n",
      "Epoch: 5/10... Training loss: 0.1196\n",
      "Epoch: 5/10... Training loss: 0.1219\n",
      "Epoch: 5/10... Training loss: 0.1192\n",
      "Epoch: 5/10... Training loss: 0.1131\n",
      "Epoch: 5/10... Training loss: 0.1228\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1184\n",
      "Epoch: 5/10... Training loss: 0.1198\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1203\n",
      "Epoch: 5/10... Training loss: 0.1209\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1246\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1209\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1225\n",
      "Epoch: 5/10... Training loss: 0.1222\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1188\n",
      "Epoch: 5/10... Training loss: 0.1155\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1206\n",
      "Epoch: 5/10... Training loss: 0.1148\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1157\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1096\n",
      "Epoch: 5/10... Training loss: 0.1226\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1193\n",
      "Epoch: 5/10... Training loss: 0.1244\n",
      "Epoch: 5/10... Training loss: 0.1163\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1107\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1222\n",
      "Epoch: 5/10... Training loss: 0.1216\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1243\n",
      "Epoch: 5/10... Training loss: 0.1150\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1199\n",
      "Epoch: 5/10... Training loss: 0.1218\n",
      "Epoch: 5/10... Training loss: 0.1108\n",
      "Epoch: 5/10... Training loss: 0.1157\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1135\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1196\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1127\n",
      "Epoch: 5/10... Training loss: 0.1202\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1195\n",
      "Epoch: 5/10... Training loss: 0.1200\n",
      "Epoch: 5/10... Training loss: 0.1211\n",
      "Epoch: 5/10... Training loss: 0.1097\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1194\n",
      "Epoch: 5/10... Training loss: 0.1199\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1098\n",
      "Epoch: 5/10... Training loss: 0.1131\n",
      "Epoch: 5/10... Training loss: 0.1129\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1220\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1195\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1111\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1132\n",
      "Epoch: 5/10... Training loss: 0.1221\n",
      "Epoch: 5/10... Training loss: 0.1181\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1113\n",
      "Epoch: 5/10... Training loss: 0.1101\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1217\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1216\n",
      "Epoch: 5/10... Training loss: 0.1208\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1113\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1120\n",
      "Epoch: 5/10... Training loss: 0.1204\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1122\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1119\n",
      "Epoch: 5/10... Training loss: 0.1233\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1125\n",
      "Epoch: 5/10... Training loss: 0.1085\n",
      "Epoch: 5/10... Training loss: 0.1218\n",
      "Epoch: 5/10... Training loss: 0.1183\n",
      "Epoch: 5/10... Training loss: 0.1211\n",
      "Epoch: 5/10... Training loss: 0.1211\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1198\n",
      "Epoch: 5/10... Training loss: 0.1059\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1168\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1173\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1199\n",
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1116\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1196\n",
      "Epoch: 5/10... Training loss: 0.1127\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1204\n",
      "Epoch: 5/10... Training loss: 0.1198\n",
      "Epoch: 5/10... Training loss: 0.1118\n",
      "Epoch: 5/10... Training loss: 0.1203\n",
      "Epoch: 5/10... Training loss: 0.1196\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1216\n",
      "Epoch: 5/10... Training loss: 0.1188\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1223\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1218\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1115\n",
      "Epoch: 5/10... Training loss: 0.1118\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1229\n",
      "Epoch: 5/10... Training loss: 0.1136\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1105\n",
      "Epoch: 5/10... Training loss: 0.1150\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1090\n",
      "Epoch: 5/10... Training loss: 0.1203\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1130\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1205\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1201\n",
      "Epoch: 5/10... Training loss: 0.1239\n",
      "Epoch: 5/10... Training loss: 0.1136\n",
      "Epoch: 5/10... Training loss: 0.1237\n",
      "Epoch: 5/10... Training loss: 0.1181\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1157\n",
      "Epoch: 5/10... Training loss: 0.1139\n",
      "Epoch: 5/10... Training loss: 0.1196\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1181\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1206\n",
      "Epoch: 5/10... Training loss: 0.1209\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1155\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1125\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1133\n",
      "Epoch: 5/10... Training loss: 0.1234\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1120\n",
      "Epoch: 5/10... Training loss: 0.1163\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1191\n",
      "Epoch: 5/10... Training loss: 0.1193\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1173\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1223\n",
      "Epoch: 5/10... Training loss: 0.1138\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1155\n",
      "Epoch: 5/10... Training loss: 0.1123\n",
      "Epoch: 5/10... Training loss: 0.1131\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1150\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1133\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1122\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1107\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1130\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1099\n",
      "Epoch: 5/10... Training loss: 0.1116\n",
      "Epoch: 5/10... Training loss: 0.1086\n",
      "Epoch: 5/10... Training loss: 0.1206\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1079\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1138\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1226\n",
      "Epoch: 5/10... Training loss: 0.1132\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1208\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1128\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1130\n",
      "Epoch: 5/10... Training loss: 0.1168\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1189\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 5/10... Training loss: 0.1123\n",
      "Epoch: 5/10... Training loss: 0.1207\n",
      "Epoch: 5/10... Training loss: 0.1111\n",
      "Epoch: 5/10... Training loss: 0.1139\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1114\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1209\n",
      "Epoch: 5/10... Training loss: 0.1193\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1191\n",
      "Epoch: 5/10... Training loss: 0.1121\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1221\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1213\n",
      "Epoch: 5/10... Training loss: 0.1219\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1199\n",
      "Epoch: 5/10... Training loss: 0.1185\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1148\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1106\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1122\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1224\n",
      "Epoch: 5/10... Training loss: 0.1184\n",
      "Epoch: 5/10... Training loss: 0.1107\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1186\n",
      "Epoch: 5/10... Training loss: 0.1214\n",
      "Epoch: 5/10... Training loss: 0.1134\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1235\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1092\n",
      "Epoch: 5/10... Training loss: 0.1183\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1194\n",
      "Epoch: 5/10... Training loss: 0.1117\n",
      "Epoch: 5/10... Training loss: 0.1102\n",
      "Epoch: 5/10... Training loss: 0.1113\n",
      "Epoch: 5/10... Training loss: 0.1173\n",
      "Epoch: 5/10... Training loss: 0.1148\n",
      "Epoch: 5/10... Training loss: 0.1112\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 5/10... Training loss: 0.1202\n",
      "Epoch: 5/10... Training loss: 0.1158\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 5/10... Training loss: 0.1123\n",
      "Epoch: 5/10... Training loss: 0.1183\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1168\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1214\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1224\n",
      "Epoch: 5/10... Training loss: 0.1138\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1128\n",
      "Epoch: 5/10... Training loss: 0.1141\n",
      "Epoch: 5/10... Training loss: 0.1107\n",
      "Epoch: 5/10... Training loss: 0.1139\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1202\n",
      "Epoch: 5/10... Training loss: 0.1116\n",
      "Epoch: 5/10... Training loss: 0.1170\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1138\n",
      "Epoch: 5/10... Training loss: 0.1132\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1173\n",
      "Epoch: 5/10... Training loss: 0.1145\n",
      "Epoch: 5/10... Training loss: 0.1192\n",
      "Epoch: 5/10... Training loss: 0.1137\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1167\n",
      "Epoch: 5/10... Training loss: 0.1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1146\n",
      "Epoch: 5/10... Training loss: 0.1193\n",
      "Epoch: 5/10... Training loss: 0.1182\n",
      "Epoch: 5/10... Training loss: 0.1150\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1106\n",
      "Epoch: 5/10... Training loss: 0.1100\n",
      "Epoch: 5/10... Training loss: 0.1174\n",
      "Epoch: 5/10... Training loss: 0.1163\n",
      "Epoch: 5/10... Training loss: 0.1147\n",
      "Epoch: 5/10... Training loss: 0.1200\n",
      "Epoch: 5/10... Training loss: 0.1132\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1127\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1212\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1094\n",
      "Epoch: 5/10... Training loss: 0.1142\n",
      "Epoch: 5/10... Training loss: 0.1207\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1191\n",
      "Epoch: 5/10... Training loss: 0.1126\n",
      "Epoch: 5/10... Training loss: 0.1197\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1200\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1160\n",
      "Epoch: 5/10... Training loss: 0.1128\n",
      "Epoch: 5/10... Training loss: 0.1119\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1126\n",
      "Epoch: 5/10... Training loss: 0.1133\n",
      "Epoch: 5/10... Training loss: 0.1183\n",
      "Epoch: 5/10... Training loss: 0.1164\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1159\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1188\n",
      "Epoch: 5/10... Training loss: 0.1234\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1210\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1131\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1188\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1195\n",
      "Epoch: 5/10... Training loss: 0.1134\n",
      "Epoch: 5/10... Training loss: 0.1121\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1151\n",
      "Epoch: 5/10... Training loss: 0.1204\n",
      "Epoch: 5/10... Training loss: 0.1155\n",
      "Epoch: 5/10... Training loss: 0.1122\n",
      "Epoch: 5/10... Training loss: 0.1165\n",
      "Epoch: 5/10... Training loss: 0.1187\n",
      "Epoch: 5/10... Training loss: 0.1179\n",
      "Epoch: 5/10... Training loss: 0.1152\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1162\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1130\n",
      "Epoch: 5/10... Training loss: 0.1175\n",
      "Epoch: 5/10... Training loss: 0.1176\n",
      "Epoch: 5/10... Training loss: 0.1113\n",
      "Epoch: 5/10... Training loss: 0.1132\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1139\n",
      "Epoch: 5/10... Training loss: 0.1166\n",
      "Epoch: 5/10... Training loss: 0.1190\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1172\n",
      "Epoch: 5/10... Training loss: 0.1215\n",
      "Epoch: 5/10... Training loss: 0.1107\n",
      "Epoch: 5/10... Training loss: 0.1144\n",
      "Epoch: 5/10... Training loss: 0.1134\n",
      "Epoch: 5/10... Training loss: 0.1177\n",
      "Epoch: 5/10... Training loss: 0.1127\n",
      "Epoch: 5/10... Training loss: 0.1140\n",
      "Epoch: 5/10... Training loss: 0.1173\n",
      "Epoch: 5/10... Training loss: 0.1133\n",
      "Epoch: 5/10... Training loss: 0.1178\n",
      "Epoch: 5/10... Training loss: 0.1180\n",
      "Epoch: 5/10... Training loss: 0.1154\n",
      "Epoch: 5/10... Training loss: 0.1219\n",
      "Epoch: 5/10... Training loss: 0.1200\n",
      "Epoch: 5/10... Training loss: 0.1148\n",
      "Epoch: 5/10... Training loss: 0.1169\n",
      "Epoch: 5/10... Training loss: 0.1171\n",
      "Epoch: 5/10... Training loss: 0.1153\n",
      "Epoch: 5/10... Training loss: 0.1156\n",
      "Epoch: 5/10... Training loss: 0.1118\n",
      "Epoch: 5/10... Training loss: 0.1143\n",
      "Epoch: 5/10... Training loss: 0.1161\n",
      "Epoch: 5/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1124\n",
      "Epoch: 6/10... Training loss: 0.1175\n",
      "Epoch: 6/10... Training loss: 0.1182\n",
      "Epoch: 6/10... Training loss: 0.1106\n",
      "Epoch: 6/10... Training loss: 0.1238\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1159\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1154\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1096\n",
      "Epoch: 6/10... Training loss: 0.1120\n",
      "Epoch: 6/10... Training loss: 0.1188\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1171\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1154\n",
      "Epoch: 6/10... Training loss: 0.1188\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1180\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1170\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1188\n",
      "Epoch: 6/10... Training loss: 0.1175\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1187\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1086\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1128\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1188\n",
      "Epoch: 6/10... Training loss: 0.1159\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1207\n",
      "Epoch: 6/10... Training loss: 0.1201\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1121\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1214\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1206\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1190\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1115\n",
      "Epoch: 6/10... Training loss: 0.1069\n",
      "Epoch: 6/10... Training loss: 0.1076\n",
      "Epoch: 6/10... Training loss: 0.1112\n",
      "Epoch: 6/10... Training loss: 0.1185\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1164\n",
      "Epoch: 6/10... Training loss: 0.1156\n",
      "Epoch: 6/10... Training loss: 0.1110\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1193\n",
      "Epoch: 6/10... Training loss: 0.1108\n",
      "Epoch: 6/10... Training loss: 0.1187\n",
      "Epoch: 6/10... Training loss: 0.1189\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1089\n",
      "Epoch: 6/10... Training loss: 0.1172\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1246\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1249\n",
      "Epoch: 6/10... Training loss: 0.1171\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1179\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1205\n",
      "Epoch: 6/10... Training loss: 0.1172\n",
      "Epoch: 6/10... Training loss: 0.1218\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1178\n",
      "Epoch: 6/10... Training loss: 0.1167\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1230\n",
      "Epoch: 6/10... Training loss: 0.1166\n",
      "Epoch: 6/10... Training loss: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1200\n",
      "Epoch: 6/10... Training loss: 0.1153\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1186\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1153\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1178\n",
      "Epoch: 6/10... Training loss: 0.1198\n",
      "Epoch: 6/10... Training loss: 0.1194\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1096\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1203\n",
      "Epoch: 6/10... Training loss: 0.1116\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1231\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1192\n",
      "Epoch: 6/10... Training loss: 0.1182\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1125\n",
      "Epoch: 6/10... Training loss: 0.1111\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1078\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1123\n",
      "Epoch: 6/10... Training loss: 0.1208\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1147\n",
      "Epoch: 6/10... Training loss: 0.1153\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1251\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1089\n",
      "Epoch: 6/10... Training loss: 0.1167\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1197\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1184\n",
      "Epoch: 6/10... Training loss: 0.1108\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1108\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1185\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1126\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1129\n",
      "Epoch: 6/10... Training loss: 0.1209\n",
      "Epoch: 6/10... Training loss: 0.1123\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1171\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1121\n",
      "Epoch: 6/10... Training loss: 0.1097\n",
      "Epoch: 6/10... Training loss: 0.1191\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1118\n",
      "Epoch: 6/10... Training loss: 0.1180\n",
      "Epoch: 6/10... Training loss: 0.1191\n",
      "Epoch: 6/10... Training loss: 0.1183\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1181\n",
      "Epoch: 6/10... Training loss: 0.1095\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1203\n",
      "Epoch: 6/10... Training loss: 0.1176\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1067\n",
      "Epoch: 6/10... Training loss: 0.1086\n",
      "Epoch: 6/10... Training loss: 0.1125\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1167\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1187\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1164\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1170\n",
      "Epoch: 6/10... Training loss: 0.1112\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1101\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1114\n",
      "Epoch: 6/10... Training loss: 0.1102\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1159\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1068\n",
      "Epoch: 6/10... Training loss: 0.1166\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1087\n",
      "Epoch: 6/10... Training loss: 0.1184\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1154\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1099\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1154\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1110\n",
      "Epoch: 6/10... Training loss: 0.1124\n",
      "Epoch: 6/10... Training loss: 0.1160\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1158\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1101\n",
      "Epoch: 6/10... Training loss: 0.1174\n",
      "Epoch: 6/10... Training loss: 0.1208\n",
      "Epoch: 6/10... Training loss: 0.1088\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1124\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1183\n",
      "Epoch: 6/10... Training loss: 0.1099\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1167\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1163\n",
      "Epoch: 6/10... Training loss: 0.1121\n",
      "Epoch: 6/10... Training loss: 0.1164\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1169\n",
      "Epoch: 6/10... Training loss: 0.1170\n",
      "Epoch: 6/10... Training loss: 0.1187\n",
      "Epoch: 6/10... Training loss: 0.1129\n",
      "Epoch: 6/10... Training loss: 0.1105\n",
      "Epoch: 6/10... Training loss: 0.1192\n",
      "Epoch: 6/10... Training loss: 0.1101\n",
      "Epoch: 6/10... Training loss: 0.1097\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1178\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1078\n",
      "Epoch: 6/10... Training loss: 0.1205\n",
      "Epoch: 6/10... Training loss: 0.1166\n",
      "Epoch: 6/10... Training loss: 0.1153\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1107\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1078\n",
      "Epoch: 6/10... Training loss: 0.1079\n",
      "Epoch: 6/10... Training loss: 0.1069\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1213\n",
      "Epoch: 6/10... Training loss: 0.1176\n",
      "Epoch: 6/10... Training loss: 0.1089\n",
      "Epoch: 6/10... Training loss: 0.1196\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1097\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1201\n",
      "Epoch: 6/10... Training loss: 0.1181\n",
      "Epoch: 6/10... Training loss: 0.1177\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1063\n",
      "Epoch: 6/10... Training loss: 0.1153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10... Training loss: 0.1115\n",
      "Epoch: 6/10... Training loss: 0.1112\n",
      "Epoch: 6/10... Training loss: 0.1098\n",
      "Epoch: 6/10... Training loss: 0.1179\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1147\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1187\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1123\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1175\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1124\n",
      "Epoch: 6/10... Training loss: 0.1126\n",
      "Epoch: 6/10... Training loss: 0.1184\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1182\n",
      "Epoch: 6/10... Training loss: 0.1175\n",
      "Epoch: 6/10... Training loss: 0.1084\n",
      "Epoch: 6/10... Training loss: 0.1082\n",
      "Epoch: 6/10... Training loss: 0.1186\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1161\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1088\n",
      "Epoch: 6/10... Training loss: 0.1186\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1106\n",
      "Epoch: 6/10... Training loss: 0.1097\n",
      "Epoch: 6/10... Training loss: 0.1125\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1170\n",
      "Epoch: 6/10... Training loss: 0.1112\n",
      "Epoch: 6/10... Training loss: 0.1159\n",
      "Epoch: 6/10... Training loss: 0.1126\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1147\n",
      "Epoch: 6/10... Training loss: 0.1115\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1101\n",
      "Epoch: 6/10... Training loss: 0.1089\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1098\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1181\n",
      "Epoch: 6/10... Training loss: 0.1175\n",
      "Epoch: 6/10... Training loss: 0.1056\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1109\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1107\n",
      "Epoch: 6/10... Training loss: 0.1164\n",
      "Epoch: 6/10... Training loss: 0.1160\n",
      "Epoch: 6/10... Training loss: 0.1121\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1129\n",
      "Epoch: 6/10... Training loss: 0.1202\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1170\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1145\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1161\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1106\n",
      "Epoch: 6/10... Training loss: 0.1191\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1113\n",
      "Epoch: 6/10... Training loss: 0.1164\n",
      "Epoch: 6/10... Training loss: 0.1080\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1108\n",
      "Epoch: 6/10... Training loss: 0.1080\n",
      "Epoch: 6/10... Training loss: 0.1111\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1083\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1128\n",
      "Epoch: 6/10... Training loss: 0.1185\n",
      "Epoch: 6/10... Training loss: 0.1110\n",
      "Epoch: 6/10... Training loss: 0.1105\n",
      "Epoch: 6/10... Training loss: 0.1174\n",
      "Epoch: 6/10... Training loss: 0.1101\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1174\n",
      "Epoch: 6/10... Training loss: 0.1120\n",
      "Epoch: 6/10... Training loss: 0.1174\n",
      "Epoch: 6/10... Training loss: 0.1191\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1161\n",
      "Epoch: 6/10... Training loss: 0.1140\n",
      "Epoch: 6/10... Training loss: 0.1155\n",
      "Epoch: 6/10... Training loss: 0.1167\n",
      "Epoch: 6/10... Training loss: 0.1132\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1126\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1169\n",
      "Epoch: 6/10... Training loss: 0.1156\n",
      "Epoch: 6/10... Training loss: 0.1121\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1103\n",
      "Epoch: 6/10... Training loss: 0.1169\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1102\n",
      "Epoch: 6/10... Training loss: 0.1102\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1168\n",
      "Epoch: 6/10... Training loss: 0.1128\n",
      "Epoch: 6/10... Training loss: 0.1118\n",
      "Epoch: 6/10... Training loss: 0.1118\n",
      "Epoch: 6/10... Training loss: 0.1189\n",
      "Epoch: 6/10... Training loss: 0.1109\n",
      "Epoch: 6/10... Training loss: 0.1073\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1136\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1069\n",
      "Epoch: 6/10... Training loss: 0.1172\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1179\n",
      "Epoch: 6/10... Training loss: 0.1149\n",
      "Epoch: 6/10... Training loss: 0.1173\n",
      "Epoch: 6/10... Training loss: 0.1118\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1193\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1116\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1096\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1082\n",
      "Epoch: 6/10... Training loss: 0.1063\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1146\n",
      "Epoch: 6/10... Training loss: 0.1160\n",
      "Epoch: 6/10... Training loss: 0.1079\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1172\n",
      "Epoch: 6/10... Training loss: 0.1067\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1144\n",
      "Epoch: 6/10... Training loss: 0.1129\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1070\n",
      "Epoch: 6/10... Training loss: 0.1110\n",
      "Epoch: 6/10... Training loss: 0.1128\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1090\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1111\n",
      "Epoch: 6/10... Training loss: 0.1102\n",
      "Epoch: 6/10... Training loss: 0.1122\n",
      "Epoch: 6/10... Training loss: 0.1110\n",
      "Epoch: 6/10... Training loss: 0.1141\n",
      "Epoch: 6/10... Training loss: 0.1127\n",
      "Epoch: 6/10... Training loss: 0.1165\n",
      "Epoch: 6/10... Training loss: 0.1184\n",
      "Epoch: 6/10... Training loss: 0.1106\n",
      "Epoch: 6/10... Training loss: 0.1137\n",
      "Epoch: 6/10... Training loss: 0.1096\n",
      "Epoch: 6/10... Training loss: 0.1104\n",
      "Epoch: 6/10... Training loss: 0.1125\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1134\n",
      "Epoch: 6/10... Training loss: 0.1058\n",
      "Epoch: 6/10... Training loss: 0.1194\n",
      "Epoch: 6/10... Training loss: 0.1126\n",
      "Epoch: 6/10... Training loss: 0.1166\n",
      "Epoch: 6/10... Training loss: 0.1160\n",
      "Epoch: 6/10... Training loss: 0.1161\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1157\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10... Training loss: 0.1080\n",
      "Epoch: 6/10... Training loss: 0.1117\n",
      "Epoch: 6/10... Training loss: 0.1114\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1150\n",
      "Epoch: 6/10... Training loss: 0.1143\n",
      "Epoch: 6/10... Training loss: 0.1162\n",
      "Epoch: 6/10... Training loss: 0.1139\n",
      "Epoch: 6/10... Training loss: 0.1096\n",
      "Epoch: 6/10... Training loss: 0.1088\n",
      "Epoch: 6/10... Training loss: 0.1099\n",
      "Epoch: 6/10... Training loss: 0.1188\n",
      "Epoch: 6/10... Training loss: 0.1100\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1154\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1124\n",
      "Epoch: 6/10... Training loss: 0.1074\n",
      "Epoch: 6/10... Training loss: 0.1094\n",
      "Epoch: 6/10... Training loss: 0.1152\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1119\n",
      "Epoch: 6/10... Training loss: 0.1197\n",
      "Epoch: 6/10... Training loss: 0.1133\n",
      "Epoch: 6/10... Training loss: 0.1148\n",
      "Epoch: 6/10... Training loss: 0.1062\n",
      "Epoch: 6/10... Training loss: 0.1072\n",
      "Epoch: 6/10... Training loss: 0.1151\n",
      "Epoch: 6/10... Training loss: 0.1138\n",
      "Epoch: 6/10... Training loss: 0.1057\n",
      "Epoch: 6/10... Training loss: 0.1105\n",
      "Epoch: 6/10... Training loss: 0.1118\n",
      "Epoch: 6/10... Training loss: 0.1108\n",
      "Epoch: 6/10... Training loss: 0.1055\n",
      "Epoch: 6/10... Training loss: 0.1130\n",
      "Epoch: 6/10... Training loss: 0.1131\n",
      "Epoch: 6/10... Training loss: 0.1169\n",
      "Epoch: 6/10... Training loss: 0.1147\n",
      "Epoch: 6/10... Training loss: 0.1142\n",
      "Epoch: 6/10... Training loss: 0.1081\n",
      "Epoch: 6/10... Training loss: 0.1195\n",
      "Epoch: 6/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1149\n",
      "Epoch: 7/10... Training loss: 0.1133\n",
      "Epoch: 7/10... Training loss: 0.1157\n",
      "Epoch: 7/10... Training loss: 0.1054\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1133\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1079\n",
      "Epoch: 7/10... Training loss: 0.1172\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1156\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1176\n",
      "Epoch: 7/10... Training loss: 0.1149\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1103\n",
      "Epoch: 7/10... Training loss: 0.1184\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1148\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1106\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1097\n",
      "Epoch: 7/10... Training loss: 0.1177\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1088\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1150\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1156\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1200\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1165\n",
      "Epoch: 7/10... Training loss: 0.1075\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1087\n",
      "Epoch: 7/10... Training loss: 0.1159\n",
      "Epoch: 7/10... Training loss: 0.1166\n",
      "Epoch: 7/10... Training loss: 0.1149\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1049\n",
      "Epoch: 7/10... Training loss: 0.1080\n",
      "Epoch: 7/10... Training loss: 0.1081\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1161\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1118\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1118\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1119\n",
      "Epoch: 7/10... Training loss: 0.1141\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1109\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1197\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1041\n",
      "Epoch: 7/10... Training loss: 0.1082\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1103\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1037\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1121\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1072\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1046\n",
      "Epoch: 7/10... Training loss: 0.1106\n",
      "Epoch: 7/10... Training loss: 0.1093\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1121\n",
      "Epoch: 7/10... Training loss: 0.1119\n",
      "Epoch: 7/10... Training loss: 0.1148\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1129\n",
      "Epoch: 7/10... Training loss: 0.1153\n",
      "Epoch: 7/10... Training loss: 0.1084\n",
      "Epoch: 7/10... Training loss: 0.1181\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1070\n",
      "Epoch: 7/10... Training loss: 0.1142\n",
      "Epoch: 7/10... Training loss: 0.1182\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1157\n",
      "Epoch: 7/10... Training loss: 0.1081\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1187\n",
      "Epoch: 7/10... Training loss: 0.1084\n",
      "Epoch: 7/10... Training loss: 0.1176\n",
      "Epoch: 7/10... Training loss: 0.1155\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1074\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1150\n",
      "Epoch: 7/10... Training loss: 0.1195\n",
      "Epoch: 7/10... Training loss: 0.1129\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1114\n",
      "Epoch: 7/10... Training loss: 0.1153\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1202\n",
      "Epoch: 7/10... Training loss: 0.1169\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10... Training loss: 0.1083\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1168\n",
      "Epoch: 7/10... Training loss: 0.1070\n",
      "Epoch: 7/10... Training loss: 0.1106\n",
      "Epoch: 7/10... Training loss: 0.1109\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1140\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1148\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1095\n",
      "Epoch: 7/10... Training loss: 0.1114\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1181\n",
      "Epoch: 7/10... Training loss: 0.1089\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1110\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1133\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1163\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1140\n",
      "Epoch: 7/10... Training loss: 0.1109\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1050\n",
      "Epoch: 7/10... Training loss: 0.1078\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1075\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1218\n",
      "Epoch: 7/10... Training loss: 0.1163\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1065\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1089\n",
      "Epoch: 7/10... Training loss: 0.1072\n",
      "Epoch: 7/10... Training loss: 0.1095\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1189\n",
      "Epoch: 7/10... Training loss: 0.1084\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1068\n",
      "Epoch: 7/10... Training loss: 0.1091\n",
      "Epoch: 7/10... Training loss: 0.1153\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1078\n",
      "Epoch: 7/10... Training loss: 0.1201\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1094\n",
      "Epoch: 7/10... Training loss: 0.1121\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1141\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1156\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1097\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1192\n",
      "Epoch: 7/10... Training loss: 0.1076\n",
      "Epoch: 7/10... Training loss: 0.1097\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1159\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1178\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1080\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1018\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1181\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1118\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1175\n",
      "Epoch: 7/10... Training loss: 0.1155\n",
      "Epoch: 7/10... Training loss: 0.1084\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1076\n",
      "Epoch: 7/10... Training loss: 0.1079\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1200\n",
      "Epoch: 7/10... Training loss: 0.1071\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1119\n",
      "Epoch: 7/10... Training loss: 0.1098\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1051\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1119\n",
      "Epoch: 7/10... Training loss: 0.1095\n",
      "Epoch: 7/10... Training loss: 0.1078\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1172\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1133\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1165\n",
      "Epoch: 7/10... Training loss: 0.1109\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1087\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1064\n",
      "Epoch: 7/10... Training loss: 0.1069\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1204\n",
      "Epoch: 7/10... Training loss: 0.1080\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1140\n",
      "Epoch: 7/10... Training loss: 0.1141\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1068\n",
      "Epoch: 7/10... Training loss: 0.1110\n",
      "Epoch: 7/10... Training loss: 0.1177\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1098\n",
      "Epoch: 7/10... Training loss: 0.1094\n",
      "Epoch: 7/10... Training loss: 0.1073\n",
      "Epoch: 7/10... Training loss: 0.1063\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1074\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1114\n",
      "Epoch: 7/10... Training loss: 0.1097\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1118\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1076\n",
      "Epoch: 7/10... Training loss: 0.1082\n",
      "Epoch: 7/10... Training loss: 0.1057\n",
      "Epoch: 7/10... Training loss: 0.1088\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1070\n",
      "Epoch: 7/10... Training loss: 0.1130\n",
      "Epoch: 7/10... Training loss: 0.1110\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1103\n",
      "Epoch: 7/10... Training loss: 0.1103\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1141\n",
      "Epoch: 7/10... Training loss: 0.1110\n",
      "Epoch: 7/10... Training loss: 0.1068\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1168\n",
      "Epoch: 7/10... Training loss: 0.1118\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1055\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1079\n",
      "Epoch: 7/10... Training loss: 0.1139\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1129\n",
      "Epoch: 7/10... Training loss: 0.1115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1062\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1091\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 7/10... Training loss: 0.1077\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1082\n",
      "Epoch: 7/10... Training loss: 0.1109\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1134\n",
      "Epoch: 7/10... Training loss: 0.1093\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1182\n",
      "Epoch: 7/10... Training loss: 0.1063\n",
      "Epoch: 7/10... Training loss: 0.1187\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1093\n",
      "Epoch: 7/10... Training loss: 0.1094\n",
      "Epoch: 7/10... Training loss: 0.1154\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1132\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1067\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 7/10... Training loss: 0.1091\n",
      "Epoch: 7/10... Training loss: 0.1068\n",
      "Epoch: 7/10... Training loss: 0.1137\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1062\n",
      "Epoch: 7/10... Training loss: 0.1142\n",
      "Epoch: 7/10... Training loss: 0.1121\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1146\n",
      "Epoch: 7/10... Training loss: 0.1149\n",
      "Epoch: 7/10... Training loss: 0.1129\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1098\n",
      "Epoch: 7/10... Training loss: 0.1147\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1051\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1025\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1153\n",
      "Epoch: 7/10... Training loss: 0.1104\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1190\n",
      "Epoch: 7/10... Training loss: 0.1155\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1140\n",
      "Epoch: 7/10... Training loss: 0.1076\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1086\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1119\n",
      "Epoch: 7/10... Training loss: 0.1079\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1071\n",
      "Epoch: 7/10... Training loss: 0.1078\n",
      "Epoch: 7/10... Training loss: 0.1094\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1067\n",
      "Epoch: 7/10... Training loss: 0.1139\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1126\n",
      "Epoch: 7/10... Training loss: 0.1065\n",
      "Epoch: 7/10... Training loss: 0.1120\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1087\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1144\n",
      "Epoch: 7/10... Training loss: 0.1166\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1150\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1091\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1149\n",
      "Epoch: 7/10... Training loss: 0.1061\n",
      "Epoch: 7/10... Training loss: 0.1072\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1065\n",
      "Epoch: 7/10... Training loss: 0.1183\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1117\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1055\n",
      "Epoch: 7/10... Training loss: 0.1074\n",
      "Epoch: 7/10... Training loss: 0.1183\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1048\n",
      "Epoch: 7/10... Training loss: 0.1129\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1165\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1112\n",
      "Epoch: 7/10... Training loss: 0.1072\n",
      "Epoch: 7/10... Training loss: 0.1101\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1088\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1107\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1103\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1085\n",
      "Epoch: 7/10... Training loss: 0.1143\n",
      "Epoch: 7/10... Training loss: 0.1156\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1145\n",
      "Epoch: 7/10... Training loss: 0.1133\n",
      "Epoch: 7/10... Training loss: 0.1139\n",
      "Epoch: 7/10... Training loss: 0.1111\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 7/10... Training loss: 0.1160\n",
      "Epoch: 7/10... Training loss: 0.1122\n",
      "Epoch: 7/10... Training loss: 0.1169\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1156\n",
      "Epoch: 7/10... Training loss: 0.1075\n",
      "Epoch: 7/10... Training loss: 0.1171\n",
      "Epoch: 7/10... Training loss: 0.1148\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1124\n",
      "Epoch: 7/10... Training loss: 0.1121\n",
      "Epoch: 7/10... Training loss: 0.1170\n",
      "Epoch: 7/10... Training loss: 0.1114\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1135\n",
      "Epoch: 7/10... Training loss: 0.1123\n",
      "Epoch: 7/10... Training loss: 0.1116\n",
      "Epoch: 7/10... Training loss: 0.1140\n",
      "Epoch: 7/10... Training loss: 0.1151\n",
      "Epoch: 7/10... Training loss: 0.1105\n",
      "Epoch: 7/10... Training loss: 0.1127\n",
      "Epoch: 7/10... Training loss: 0.1098\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1187\n",
      "Epoch: 7/10... Training loss: 0.1113\n",
      "Epoch: 7/10... Training loss: 0.1152\n",
      "Epoch: 7/10... Training loss: 0.1138\n",
      "Epoch: 7/10... Training loss: 0.1128\n",
      "Epoch: 7/10... Training loss: 0.1091\n",
      "Epoch: 7/10... Training loss: 0.1090\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1125\n",
      "Epoch: 7/10... Training loss: 0.1092\n",
      "Epoch: 7/10... Training loss: 0.1178\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1099\n",
      "Epoch: 7/10... Training loss: 0.1153\n",
      "Epoch: 7/10... Training loss: 0.1064\n",
      "Epoch: 7/10... Training loss: 0.1155\n",
      "Epoch: 7/10... Training loss: 0.1100\n",
      "Epoch: 7/10... Training loss: 0.1159\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1060\n",
      "Epoch: 7/10... Training loss: 0.1131\n",
      "Epoch: 7/10... Training loss: 0.1070\n",
      "Epoch: 7/10... Training loss: 0.1075\n",
      "Epoch: 7/10... Training loss: 0.1057\n",
      "Epoch: 7/10... Training loss: 0.1096\n",
      "Epoch: 7/10... Training loss: 0.1076\n",
      "Epoch: 7/10... Training loss: 0.1102\n",
      "Epoch: 7/10... Training loss: 0.1136\n",
      "Epoch: 7/10... Training loss: 0.1080\n",
      "Epoch: 7/10... Training loss: 0.1108\n",
      "Epoch: 7/10... Training loss: 0.1115\n",
      "Epoch: 7/10... Training loss: 0.1158\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1022\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1072\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1063\n",
      "Epoch: 8/10... Training loss: 0.1140\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1141\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1116\n",
      "Epoch: 8/10... Training loss: 0.1054\n",
      "Epoch: 8/10... Training loss: 0.1101\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1083\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1137\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1083\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1193\n",
      "Epoch: 8/10... Training loss: 0.1077\n",
      "Epoch: 8/10... Training loss: 0.1183\n",
      "Epoch: 8/10... Training loss: 0.1149\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1145\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1046\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1075\n",
      "Epoch: 8/10... Training loss: 0.1105\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1098\n",
      "Epoch: 8/10... Training loss: 0.1123\n",
      "Epoch: 8/10... Training loss: 0.1150\n",
      "Epoch: 8/10... Training loss: 0.1147\n",
      "Epoch: 8/10... Training loss: 0.1138\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1136\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1140\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1066\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1062\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1018\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1158\n",
      "Epoch: 8/10... Training loss: 0.1154\n",
      "Epoch: 8/10... Training loss: 0.1057\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1165\n",
      "Epoch: 8/10... Training loss: 0.1186\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1129\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1152\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1127\n",
      "Epoch: 8/10... Training loss: 0.1163\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1065\n",
      "Epoch: 8/10... Training loss: 0.1147\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1177\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1109\n",
      "Epoch: 8/10... Training loss: 0.1082\n",
      "Epoch: 8/10... Training loss: 0.1139\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1054\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1106\n",
      "Epoch: 8/10... Training loss: 0.1098\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1138\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1137\n",
      "Epoch: 8/10... Training loss: 0.1149\n",
      "Epoch: 8/10... Training loss: 0.1068\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1078\n",
      "Epoch: 8/10... Training loss: 0.1073\n",
      "Epoch: 8/10... Training loss: 0.1086\n",
      "Epoch: 8/10... Training loss: 0.1159\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1156\n",
      "Epoch: 8/10... Training loss: 0.1073\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1081\n",
      "Epoch: 8/10... Training loss: 0.1175\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1185\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1082\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1158\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1058\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1109\n",
      "Epoch: 8/10... Training loss: 0.1136\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1141\n",
      "Epoch: 8/10... Training loss: 0.1177\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1141\n",
      "Epoch: 8/10... Training loss: 0.1147\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1147\n",
      "Epoch: 8/10... Training loss: 0.1138\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1162\n",
      "Epoch: 8/10... Training loss: 0.1159\n",
      "Epoch: 8/10... Training loss: 0.1124\n",
      "Epoch: 8/10... Training loss: 0.1058\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1064\n",
      "Epoch: 8/10... Training loss: 0.1154\n",
      "Epoch: 8/10... Training loss: 0.1071\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1105\n",
      "Epoch: 8/10... Training loss: 0.1116\n",
      "Epoch: 8/10... Training loss: 0.1151\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1072\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1090\n",
      "Epoch: 8/10... Training loss: 0.1062\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1044\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1136\n",
      "Epoch: 8/10... Training loss: 0.1072\n",
      "Epoch: 8/10... Training loss: 0.1071\n",
      "Epoch: 8/10... Training loss: 0.1153\n",
      "Epoch: 8/10... Training loss: 0.1058\n",
      "Epoch: 8/10... Training loss: 0.1140\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1109\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1064\n",
      "Epoch: 8/10... Training loss: 0.1083\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1075\n",
      "Epoch: 8/10... Training loss: 0.1089\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1127\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1160\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1116\n",
      "Epoch: 8/10... Training loss: 0.1073\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10... Training loss: 0.1081\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1073\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1136\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1048\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1047\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1150\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1193\n",
      "Epoch: 8/10... Training loss: 0.1086\n",
      "Epoch: 8/10... Training loss: 0.1145\n",
      "Epoch: 8/10... Training loss: 0.1163\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1153\n",
      "Epoch: 8/10... Training loss: 0.1154\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1078\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1138\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1060\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1186\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1052\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1155\n",
      "Epoch: 8/10... Training loss: 0.1065\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1123\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1124\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1105\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1046\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1136\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1080\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1052\n",
      "Epoch: 8/10... Training loss: 0.1077\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1150\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1145\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1066\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1082\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1063\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1119\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1077\n",
      "Epoch: 8/10... Training loss: 0.1071\n",
      "Epoch: 8/10... Training loss: 0.1141\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1148\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1118\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1048\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1062\n",
      "Epoch: 8/10... Training loss: 0.1105\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1047\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1083\n",
      "Epoch: 8/10... Training loss: 0.1101\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1156\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1106\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1155\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1058\n",
      "Epoch: 8/10... Training loss: 0.1142\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1038\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1140\n",
      "Epoch: 8/10... Training loss: 0.1162\n",
      "Epoch: 8/10... Training loss: 0.1059\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1061\n",
      "Epoch: 8/10... Training loss: 0.1142\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1038\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1065\n",
      "Epoch: 8/10... Training loss: 0.1057\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1132\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1116\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1075\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1129\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1141\n",
      "Epoch: 8/10... Training loss: 0.1140\n",
      "Epoch: 8/10... Training loss: 0.1087\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1056\n",
      "Epoch: 8/10... Training loss: 0.1156\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1127\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1080\n",
      "Epoch: 8/10... Training loss: 0.1161\n",
      "Epoch: 8/10... Training loss: 0.1144\n",
      "Epoch: 8/10... Training loss: 0.1078\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1123\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1167\n",
      "Epoch: 8/10... Training loss: 0.1094\n",
      "Epoch: 8/10... Training loss: 0.1098\n",
      "Epoch: 8/10... Training loss: 0.1062\n",
      "Epoch: 8/10... Training loss: 0.1071\n",
      "Epoch: 8/10... Training loss: 0.1060\n",
      "Epoch: 8/10... Training loss: 0.1092\n",
      "Epoch: 8/10... Training loss: 0.1146\n",
      "Epoch: 8/10... Training loss: 0.1098\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1137\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1161\n",
      "Epoch: 8/10... Training loss: 0.1056\n",
      "Epoch: 8/10... Training loss: 0.1163\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1065\n",
      "Epoch: 8/10... Training loss: 0.1118\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1114\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1172\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1077\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1169\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1124\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1142\n",
      "Epoch: 8/10... Training loss: 0.1090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1098\n",
      "Epoch: 8/10... Training loss: 0.1129\n",
      "Epoch: 8/10... Training loss: 0.1024\n",
      "Epoch: 8/10... Training loss: 0.1118\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1034\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1106\n",
      "Epoch: 8/10... Training loss: 0.1106\n",
      "Epoch: 8/10... Training loss: 0.1060\n",
      "Epoch: 8/10... Training loss: 0.1050\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1134\n",
      "Epoch: 8/10... Training loss: 0.1090\n",
      "Epoch: 8/10... Training loss: 0.1093\n",
      "Epoch: 8/10... Training loss: 0.1069\n",
      "Epoch: 8/10... Training loss: 0.1101\n",
      "Epoch: 8/10... Training loss: 0.1101\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1169\n",
      "Epoch: 8/10... Training loss: 0.1110\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1075\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1127\n",
      "Epoch: 8/10... Training loss: 0.1066\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1108\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1117\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1159\n",
      "Epoch: 8/10... Training loss: 0.1148\n",
      "Epoch: 8/10... Training loss: 0.1125\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1121\n",
      "Epoch: 8/10... Training loss: 0.1072\n",
      "Epoch: 8/10... Training loss: 0.1058\n",
      "Epoch: 8/10... Training loss: 0.1104\n",
      "Epoch: 8/10... Training loss: 0.1123\n",
      "Epoch: 8/10... Training loss: 0.1069\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1127\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1150\n",
      "Epoch: 8/10... Training loss: 0.1175\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1102\n",
      "Epoch: 8/10... Training loss: 0.1089\n",
      "Epoch: 8/10... Training loss: 0.1116\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1067\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1100\n",
      "Epoch: 8/10... Training loss: 0.1088\n",
      "Epoch: 8/10... Training loss: 0.1070\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1101\n",
      "Epoch: 8/10... Training loss: 0.1033\n",
      "Epoch: 8/10... Training loss: 0.1143\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1131\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1056\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1147\n",
      "Epoch: 8/10... Training loss: 0.1103\n",
      "Epoch: 8/10... Training loss: 0.1122\n",
      "Epoch: 8/10... Training loss: 0.1084\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1109\n",
      "Epoch: 8/10... Training loss: 0.1126\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1041\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1049\n",
      "Epoch: 8/10... Training loss: 0.1095\n",
      "Epoch: 8/10... Training loss: 0.1124\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1086\n",
      "Epoch: 8/10... Training loss: 0.1164\n",
      "Epoch: 8/10... Training loss: 0.1088\n",
      "Epoch: 8/10... Training loss: 0.1074\n",
      "Epoch: 8/10... Training loss: 0.1111\n",
      "Epoch: 8/10... Training loss: 0.1091\n",
      "Epoch: 8/10... Training loss: 0.1107\n",
      "Epoch: 8/10... Training loss: 0.1113\n",
      "Epoch: 8/10... Training loss: 0.1077\n",
      "Epoch: 8/10... Training loss: 0.1129\n",
      "Epoch: 8/10... Training loss: 0.1096\n",
      "Epoch: 8/10... Training loss: 0.1097\n",
      "Epoch: 8/10... Training loss: 0.1021\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1115\n",
      "Epoch: 8/10... Training loss: 0.1055\n",
      "Epoch: 8/10... Training loss: 0.1120\n",
      "Epoch: 8/10... Training loss: 0.1081\n",
      "Epoch: 8/10... Training loss: 0.1130\n",
      "Epoch: 8/10... Training loss: 0.1135\n",
      "Epoch: 8/10... Training loss: 0.1123\n",
      "Epoch: 8/10... Training loss: 0.1088\n",
      "Epoch: 8/10... Training loss: 0.1128\n",
      "Epoch: 8/10... Training loss: 0.1064\n",
      "Epoch: 8/10... Training loss: 0.1081\n",
      "Epoch: 8/10... Training loss: 0.1046\n",
      "Epoch: 8/10... Training loss: 0.1129\n",
      "Epoch: 8/10... Training loss: 0.1112\n",
      "Epoch: 8/10... Training loss: 0.1133\n",
      "Epoch: 8/10... Training loss: 0.1047\n",
      "Epoch: 8/10... Training loss: 0.1083\n",
      "Epoch: 8/10... Training loss: 0.1076\n",
      "Epoch: 8/10... Training loss: 0.1099\n",
      "Epoch: 8/10... Training loss: 0.1079\n",
      "Epoch: 8/10... Training loss: 0.1183\n",
      "Epoch: 9/10... Training loss: 0.1142\n",
      "Epoch: 9/10... Training loss: 0.1073\n",
      "Epoch: 9/10... Training loss: 0.1056\n",
      "Epoch: 9/10... Training loss: 0.1135\n",
      "Epoch: 9/10... Training loss: 0.1137\n",
      "Epoch: 9/10... Training loss: 0.1042\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1049\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1046\n",
      "Epoch: 9/10... Training loss: 0.1126\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1129\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1086\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1117\n",
      "Epoch: 9/10... Training loss: 0.1123\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1132\n",
      "Epoch: 9/10... Training loss: 0.1132\n",
      "Epoch: 9/10... Training loss: 0.1062\n",
      "Epoch: 9/10... Training loss: 0.1150\n",
      "Epoch: 9/10... Training loss: 0.1161\n",
      "Epoch: 9/10... Training loss: 0.1157\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1135\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1062\n",
      "Epoch: 9/10... Training loss: 0.1120\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1167\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1132\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1078\n",
      "Epoch: 9/10... Training loss: 0.1077\n",
      "Epoch: 9/10... Training loss: 0.1123\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1134\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1133\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1142\n",
      "Epoch: 9/10... Training loss: 0.1124\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1140\n",
      "Epoch: 9/10... Training loss: 0.1133\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1037\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1036\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1120\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1055\n",
      "Epoch: 9/10... Training loss: 0.1114\n",
      "Epoch: 9/10... Training loss: 0.1104\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1155\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1050\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1106\n",
      "Epoch: 9/10... Training loss: 0.1150\n",
      "Epoch: 9/10... Training loss: 0.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1048\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1155\n",
      "Epoch: 9/10... Training loss: 0.1140\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1117\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1165\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1114\n",
      "Epoch: 9/10... Training loss: 0.1059\n",
      "Epoch: 9/10... Training loss: 0.1134\n",
      "Epoch: 9/10... Training loss: 0.1049\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1126\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1151\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1164\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1115\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1051\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1166\n",
      "Epoch: 9/10... Training loss: 0.1128\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1052\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1168\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1123\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1135\n",
      "Epoch: 9/10... Training loss: 0.1138\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1114\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1150\n",
      "Epoch: 9/10... Training loss: 0.1139\n",
      "Epoch: 9/10... Training loss: 0.1133\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1040\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1030\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1114\n",
      "Epoch: 9/10... Training loss: 0.1125\n",
      "Epoch: 9/10... Training loss: 0.1046\n",
      "Epoch: 9/10... Training loss: 0.1081\n",
      "Epoch: 9/10... Training loss: 0.1062\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1064\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1144\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1088\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1055\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1082\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1054\n",
      "Epoch: 9/10... Training loss: 0.1036\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1036\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1077\n",
      "Epoch: 9/10... Training loss: 0.1056\n",
      "Epoch: 9/10... Training loss: 0.1069\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1134\n",
      "Epoch: 9/10... Training loss: 0.1086\n",
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1063\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1052\n",
      "Epoch: 9/10... Training loss: 0.1055\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1063\n",
      "Epoch: 9/10... Training loss: 0.1026\n",
      "Epoch: 9/10... Training loss: 0.1029\n",
      "Epoch: 9/10... Training loss: 0.1023\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1106\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1088\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1053\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1135\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1109\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1058\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1154\n",
      "Epoch: 9/10... Training loss: 0.1014\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1054\n",
      "Epoch: 9/10... Training loss: 0.1056\n",
      "Epoch: 9/10... Training loss: 0.1145\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1133\n",
      "Epoch: 9/10... Training loss: 0.1148\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1137\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1117\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1128\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1066\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1140\n",
      "Epoch: 9/10... Training loss: 0.1104\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1113\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1171\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1051\n",
      "Epoch: 9/10... Training loss: 0.1137\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1034\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1038\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1056\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1152\n",
      "Epoch: 9/10... Training loss: 0.1048\n",
      "Epoch: 9/10... Training loss: 0.1082\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1064\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1051\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1142\n",
      "Epoch: 9/10... Training loss: 0.1086\n",
      "Epoch: 9/10... Training loss: 0.1055\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1073\n",
      "Epoch: 9/10... Training loss: 0.1050\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1113\n",
      "Epoch: 9/10... Training loss: 0.1095\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1087\n",
      "Epoch: 9/10... Training loss: 0.1139\n",
      "Epoch: 9/10... Training loss: 0.1107\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1106\n",
      "Epoch: 9/10... Training loss: 0.1066\n",
      "Epoch: 9/10... Training loss: 0.1067\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1047\n",
      "Epoch: 9/10... Training loss: 0.1128\n",
      "Epoch: 9/10... Training loss: 0.1095\n",
      "Epoch: 9/10... Training loss: 0.1104\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1052\n",
      "Epoch: 9/10... Training loss: 0.1121\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1073\n",
      "Epoch: 9/10... Training loss: 0.1113\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1069\n",
      "Epoch: 9/10... Training loss: 0.1104\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1029\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1058\n",
      "Epoch: 9/10... Training loss: 0.1027\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1050\n",
      "Epoch: 9/10... Training loss: 0.1044\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1054\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1064\n",
      "Epoch: 9/10... Training loss: 0.1033\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1088\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1069\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1037\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1129\n",
      "Epoch: 9/10... Training loss: 0.1127\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1095\n",
      "Epoch: 9/10... Training loss: 0.1086\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1115\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1103\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1175\n",
      "Epoch: 9/10... Training loss: 0.1125\n",
      "Epoch: 9/10... Training loss: 0.1062\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1057\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1034\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1124\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1143\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1095\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1061\n",
      "Epoch: 9/10... Training loss: 0.1059\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1137\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1109\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1064\n",
      "Epoch: 9/10... Training loss: 0.1124\n",
      "Epoch: 9/10... Training loss: 0.1066\n",
      "Epoch: 9/10... Training loss: 0.1063\n",
      "Epoch: 9/10... Training loss: 0.1126\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1174\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1077\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1078\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1122\n",
      "Epoch: 9/10... Training loss: 0.1105\n",
      "Epoch: 9/10... Training loss: 0.1042\n",
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1084\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1081\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1085\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1088\n",
      "Epoch: 9/10... Training loss: 0.1058\n",
      "Epoch: 9/10... Training loss: 0.1124\n",
      "Epoch: 9/10... Training loss: 0.1076\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1116\n",
      "Epoch: 9/10... Training loss: 0.1139\n",
      "Epoch: 9/10... Training loss: 0.1082\n",
      "Epoch: 9/10... Training loss: 0.1082\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1081\n",
      "Epoch: 9/10... Training loss: 0.1066\n",
      "Epoch: 9/10... Training loss: 0.1075\n",
      "Epoch: 9/10... Training loss: 0.1082\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1067\n",
      "Epoch: 9/10... Training loss: 0.1111\n",
      "Epoch: 9/10... Training loss: 0.1096\n",
      "Epoch: 9/10... Training loss: 0.1133\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1119\n",
      "Epoch: 9/10... Training loss: 0.1102\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1062\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1054\n",
      "Epoch: 9/10... Training loss: 0.1157\n",
      "Epoch: 9/10... Training loss: 0.1073\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1063\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1093\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1059\n",
      "Epoch: 9/10... Training loss: 0.1113\n",
      "Epoch: 9/10... Training loss: 0.1033\n",
      "Epoch: 9/10... Training loss: 0.1052\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1074\n",
      "Epoch: 9/10... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10... Training loss: 0.1131\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1091\n",
      "Epoch: 9/10... Training loss: 0.1114\n",
      "Epoch: 9/10... Training loss: 0.1090\n",
      "Epoch: 9/10... Training loss: 0.1101\n",
      "Epoch: 9/10... Training loss: 0.1083\n",
      "Epoch: 9/10... Training loss: 0.1150\n",
      "Epoch: 9/10... Training loss: 0.1112\n",
      "Epoch: 9/10... Training loss: 0.1130\n",
      "Epoch: 9/10... Training loss: 0.1063\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1029\n",
      "Epoch: 9/10... Training loss: 0.1099\n",
      "Epoch: 9/10... Training loss: 0.1037\n",
      "Epoch: 9/10... Training loss: 0.1048\n",
      "Epoch: 9/10... Training loss: 0.1042\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1126\n",
      "Epoch: 9/10... Training loss: 0.1094\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1129\n",
      "Epoch: 9/10... Training loss: 0.1009\n",
      "Epoch: 9/10... Training loss: 0.1069\n",
      "Epoch: 9/10... Training loss: 0.1115\n",
      "Epoch: 9/10... Training loss: 0.1060\n",
      "Epoch: 9/10... Training loss: 0.1067\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1053\n",
      "Epoch: 9/10... Training loss: 0.1108\n",
      "Epoch: 9/10... Training loss: 0.1071\n",
      "Epoch: 9/10... Training loss: 0.1064\n",
      "Epoch: 9/10... Training loss: 0.1100\n",
      "Epoch: 9/10... Training loss: 0.1055\n",
      "Epoch: 9/10... Training loss: 0.1070\n",
      "Epoch: 9/10... Training loss: 0.1124\n",
      "Epoch: 9/10... Training loss: 0.1137\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1079\n",
      "Epoch: 9/10... Training loss: 0.1080\n",
      "Epoch: 9/10... Training loss: 0.1059\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1013\n",
      "Epoch: 9/10... Training loss: 0.1077\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1120\n",
      "Epoch: 9/10... Training loss: 0.1110\n",
      "Epoch: 9/10... Training loss: 0.1118\n",
      "Epoch: 9/10... Training loss: 0.1140\n",
      "Epoch: 9/10... Training loss: 0.1098\n",
      "Epoch: 9/10... Training loss: 0.1120\n",
      "Epoch: 9/10... Training loss: 0.1037\n",
      "Epoch: 9/10... Training loss: 0.1072\n",
      "Epoch: 9/10... Training loss: 0.1089\n",
      "Epoch: 9/10... Training loss: 0.1129\n",
      "Epoch: 9/10... Training loss: 0.1068\n",
      "Epoch: 9/10... Training loss: 0.1056\n",
      "Epoch: 9/10... Training loss: 0.1097\n",
      "Epoch: 9/10... Training loss: 0.1092\n",
      "Epoch: 9/10... Training loss: 0.1065\n",
      "Epoch: 9/10... Training loss: 0.1125\n",
      "Epoch: 9/10... Training loss: 0.1106\n",
      "Epoch: 9/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1112\n",
      "Epoch: 10/10... Training loss: 0.1040\n",
      "Epoch: 10/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1049\n",
      "Epoch: 10/10... Training loss: 0.1044\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1134\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1129\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1152\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1027\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1114\n",
      "Epoch: 10/10... Training loss: 0.1049\n",
      "Epoch: 10/10... Training loss: 0.1038\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1039\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1043\n",
      "Epoch: 10/10... Training loss: 0.1035\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1043\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1039\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1146\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1076\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1117\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1114\n",
      "Epoch: 10/10... Training loss: 0.1141\n",
      "Epoch: 10/10... Training loss: 0.1110\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1055\n",
      "Epoch: 10/10... Training loss: 0.1046\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1055\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1133\n",
      "Epoch: 10/10... Training loss: 0.1103\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1116\n",
      "Epoch: 10/10... Training loss: 0.1127\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1156\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1128\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1058\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1159\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1045\n",
      "Epoch: 10/10... Training loss: 0.1042\n",
      "Epoch: 10/10... Training loss: 0.1135\n",
      "Epoch: 10/10... Training loss: 0.1114\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1105\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1098\n",
      "Epoch: 10/10... Training loss: 0.1123\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1015\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1092\n",
      "Epoch: 10/10... Training loss: 0.1114\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1043\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1073\n",
      "Epoch: 10/10... Training loss: 0.1089\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1144\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1158\n",
      "Epoch: 10/10... Training loss: 0.1092\n",
      "Epoch: 10/10... Training loss: 0.1108\n",
      "Epoch: 10/10... Training loss: 0.1123\n",
      "Epoch: 10/10... Training loss: 0.1136\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1108\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1123\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1065\n",
      "Epoch: 10/10... Training loss: 0.1104\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1055\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1148\n",
      "Epoch: 10/10... Training loss: 0.1097\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1136\n",
      "Epoch: 10/10... Training loss: 0.1035\n",
      "Epoch: 10/10... Training loss: 0.1121\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1125\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1049\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1063\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1036\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1065\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1125\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1139\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1057\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1026\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1040\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1042\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1115\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1047\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1102\n",
      "Epoch: 10/10... Training loss: 0.1051\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1166\n",
      "Epoch: 10/10... Training loss: 0.1038\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1126\n",
      "Epoch: 10/10... Training loss: 0.1063\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1110\n",
      "Epoch: 10/10... Training loss: 0.1131\n",
      "Epoch: 10/10... Training loss: 0.1051\n",
      "Epoch: 10/10... Training loss: 0.1124\n",
      "Epoch: 10/10... Training loss: 0.1097\n",
      "Epoch: 10/10... Training loss: 0.1076\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1007\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1135\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1108\n",
      "Epoch: 10/10... Training loss: 0.1114\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1098\n",
      "Epoch: 10/10... Training loss: 0.1050\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1122\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1107\n",
      "Epoch: 10/10... Training loss: 0.1162\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1102\n",
      "Epoch: 10/10... Training loss: 0.1040\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1122\n",
      "Epoch: 10/10... Training loss: 0.1051\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1034\n",
      "Epoch: 10/10... Training loss: 0.1025\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1026\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1046\n",
      "Epoch: 10/10... Training loss: 0.1037\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1036\n",
      "Epoch: 10/10... Training loss: 0.1045\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1108\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1115\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1065\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1105\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1129\n",
      "Epoch: 10/10... Training loss: 0.1134\n",
      "Epoch: 10/10... Training loss: 0.1047\n",
      "Epoch: 10/10... Training loss: 0.1047\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1144\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1107\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1063\n",
      "Epoch: 10/10... Training loss: 0.1057\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1043\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1097\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1045\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1125\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1073\n",
      "Epoch: 10/10... Training loss: 0.1116\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1117\n",
      "Epoch: 10/10... Training loss: 0.1045\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1106\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1115\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1059\n",
      "Epoch: 10/10... Training loss: 0.1164\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1046\n",
      "Epoch: 10/10... Training loss: 0.1107\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1097\n",
      "Epoch: 10/10... Training loss: 0.1065\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1047\n",
      "Epoch: 10/10... Training loss: 0.1123\n",
      "Epoch: 10/10... Training loss: 0.1119\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1046\n",
      "Epoch: 10/10... Training loss: 0.1089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1098\n",
      "Epoch: 10/10... Training loss: 0.1097\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1128\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1116\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1028\n",
      "Epoch: 10/10... Training loss: 0.1127\n",
      "Epoch: 10/10... Training loss: 0.1042\n",
      "Epoch: 10/10... Training loss: 0.1096\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1022\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1144\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1019\n",
      "Epoch: 10/10... Training loss: 0.1103\n",
      "Epoch: 10/10... Training loss: 0.1058\n",
      "Epoch: 10/10... Training loss: 0.1117\n",
      "Epoch: 10/10... Training loss: 0.1092\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1108\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1089\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1075\n",
      "Epoch: 10/10... Training loss: 0.1033\n",
      "Epoch: 10/10... Training loss: 0.1040\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1116\n",
      "Epoch: 10/10... Training loss: 0.1117\n",
      "Epoch: 10/10... Training loss: 0.1124\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1028\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1071\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1036\n",
      "Epoch: 10/10... Training loss: 0.1136\n",
      "Epoch: 10/10... Training loss: 0.1116\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1105\n",
      "Epoch: 10/10... Training loss: 0.1090\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1074\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1102\n",
      "Epoch: 10/10... Training loss: 0.1152\n",
      "Epoch: 10/10... Training loss: 0.1027\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1073\n",
      "Epoch: 10/10... Training loss: 0.1041\n",
      "Epoch: 10/10... Training loss: 0.1019\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1041\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1058\n",
      "Epoch: 10/10... Training loss: 0.1023\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1160\n",
      "Epoch: 10/10... Training loss: 0.1133\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1035\n",
      "Epoch: 10/10... Training loss: 0.1026\n",
      "Epoch: 10/10... Training loss: 0.1057\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1110\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1077\n",
      "Epoch: 10/10... Training loss: 0.1098\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1048\n",
      "Epoch: 10/10... Training loss: 0.1130\n",
      "Epoch: 10/10... Training loss: 0.1063\n",
      "Epoch: 10/10... Training loss: 0.1073\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1112\n",
      "Epoch: 10/10... Training loss: 0.1032\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1025\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1039\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1080\n",
      "Epoch: 10/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1040\n",
      "Epoch: 10/10... Training loss: 0.1003\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1035\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1093\n",
      "Epoch: 10/10... Training loss: 0.1044\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1007\n",
      "Epoch: 10/10... Training loss: 0.1062\n",
      "Epoch: 10/10... Training loss: 0.1137\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1030\n",
      "Epoch: 10/10... Training loss: 0.1106\n",
      "Epoch: 10/10... Training loss: 0.1089\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1120\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1099\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1153\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1081\n",
      "Epoch: 10/10... Training loss: 0.1085\n",
      "Epoch: 10/10... Training loss: 0.1055\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1107\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1078\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1073\n",
      "Epoch: 10/10... Training loss: 0.1106\n",
      "Epoch: 10/10... Training loss: 0.1063\n",
      "Epoch: 10/10... Training loss: 0.1050\n",
      "Epoch: 10/10... Training loss: 0.1076\n",
      "Epoch: 10/10... Training loss: 0.1163\n",
      "Epoch: 10/10... Training loss: 0.1020\n",
      "Epoch: 10/10... Training loss: 0.1098\n",
      "Epoch: 10/10... Training loss: 0.1067\n",
      "Epoch: 10/10... Training loss: 0.1083\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1092\n",
      "Epoch: 10/10... Training loss: 0.1135\n",
      "Epoch: 10/10... Training loss: 0.1084\n",
      "Epoch: 10/10... Training loss: 0.1087\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1050\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1100\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1082\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1023\n",
      "Epoch: 10/10... Training loss: 0.1105\n",
      "Epoch: 10/10... Training loss: 0.1058\n",
      "Epoch: 10/10... Training loss: 0.1103\n",
      "Epoch: 10/10... Training loss: 0.1088\n",
      "Epoch: 10/10... Training loss: 0.1068\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1123\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1113\n",
      "Epoch: 10/10... Training loss: 0.1060\n",
      "Epoch: 10/10... Training loss: 0.1054\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1070\n",
      "Epoch: 10/10... Training loss: 0.1109\n",
      "Epoch: 10/10... Training loss: 0.1079\n",
      "Epoch: 10/10... Training loss: 0.1053\n",
      "Epoch: 10/10... Training loss: 0.1086\n",
      "Epoch: 10/10... Training loss: 0.1046\n",
      "Epoch: 10/10... Training loss: 0.1052\n",
      "Epoch: 10/10... Training loss: 0.1148\n",
      "Epoch: 10/10... Training loss: 0.1094\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1115\n",
      "Epoch: 10/10... Training loss: 0.1091\n",
      "Epoch: 10/10... Training loss: 0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10... Training loss: 0.1112\n",
      "Epoch: 10/10... Training loss: 0.1066\n",
      "Epoch: 10/10... Training loss: 0.1056\n",
      "Epoch: 10/10... Training loss: 0.1069\n",
      "Epoch: 10/10... Training loss: 0.1061\n",
      "Epoch: 10/10... Training loss: 0.1064\n",
      "Epoch: 10/10... Training loss: 0.1107\n",
      "Epoch: 10/10... Training loss: 0.1072\n",
      "Epoch: 10/10... Training loss: 0.1020\n",
      "Epoch: 10/10... Training loss: 0.1095\n",
      "Epoch: 10/10... Training loss: 0.1101\n",
      "Epoch: 10/10... Training loss: 0.1111\n",
      "Epoch: 10/10... Training loss: 0.1106\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + 0.6 * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
